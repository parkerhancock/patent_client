interactions:
- request:
    body: '{"start": 0, "pageCount": 500, "sort": "date_publ desc", "docFamilyFiltering":
      "familyIdFiltering", "searchType": 1, "familyIdEnglishOnly": true, "familyIdFirstPreferred":
      "US-PGPUB", "familyIdSecondPreferred": "USPAT", "familyIdThirdPreferred": "FPRS",
      "showDocPerFamilyPref": "showEnglish", "queryId": 0, "tagDocSearch": false,
      "query": {"caseId": 23892567, "hl_snippets": "2", "op": "OR", "q": "\"RE43633\".PN.",
      "queryName": "\"RE43633\".PN.", "highlights": "1", "qt": "brs", "spellCheck":
      false, "viewName": "tile", "plurals": true, "britishEquivalents": true, "databaseFilters":
      [{"databaseName": "USPAT", "countryCodes": []}], "searchType": 1, "ignorePersist":
      true, "userEnteredQuery": "\"RE43633\".PN."}}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '713'
      content-type:
      - application/json
      host:
      - ppubs.uspto.gov
      user-agent:
      - Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML,
        like Gecko) Chrome/114.0.0.0 Safari/537.36
      x-requested-with:
      - XMLHttpRequest
    method: POST
    uri: https://ppubs.uspto.gov/dirsearch-public/searches/searchWithBeFamily
  response:
    content: '{"numFound":1,"perPage":500,"page":0,"totalPages":0,"hlSnippets":0,"sort":null,"query":{"id":null,"caseId":23892567,"numResults":1,"ignorePersist":true,"fq":null,"databaseFilters":[{"databaseName":"USPAT","countryCodes":[]}],"q":"\"RE43633\".PN.","queryName":"\"RE43633\".PN.","userEnteredQuery":"\"RE43633\".PN.","viewName":"tile","op":"OR","highlights":"1","plurals":true,"britishEquivalents":true,"searchType":1,"excludeResultsAfter":null,"dateCreated":null,"deleteIn":false,"expand":true,"expandSort":"group_sort_date
      asc, id desc ","expandRows":"100","expandTrackDocScores":true,"expandTrackMaxScore":true,"termGraph":null,"hl":false,"fl":null,"originalQuery":"\"RE43633\".PN.","error":null,"terms":["\"re43633\""],"facets":[],"pNumber":null,"hl_fl":null},"duration":61,"highlightingTime":0,"cursorMarker":"AoJwwPKkx7kCNzIyNzI4Mjg4IVVTLVVTLVJFMDQzNjMz","totalResults":1,"numberOfFamilies":1,"error":null,"patents":[{"guid":"US-RE43633-E","publicationReferenceDocumentNumber":"RE43633","compositeId":"22728288!US-US-RE043633","publicationReferenceDocumentNumber1":"RE043633","datePublishedKwicHits":null,"datePublished":"2012-09-04T00:00:00Z","inventionTitle":"System
      and method for linking streams of multimedia data to reference material for
      display","type":"USPAT","mainClassificationCode":"704/3","applicantName":null,"assigneeName":["Sentius
      International LLC"],"uspcFullClassificationFlattened":"345/157;704/10;704/9;707/999.003;715/255;707/758;704/1;345/160;715/856","ipcCodeFlattened":"G06F17/30;G06F17/28","cpcInventiveFlattened":"G09B19/06;G09B5/065","cpcAdditionalFlattened":null,"applicationFilingDate":["2009-06-08T00:00:00Z"],"applicationFilingDateKwicHits":null,"relatedApplFilingDate":["2005-02-24T00:00:00Z","1994-02-16T00:00:00Z"],"primaryExaminer":"Hudspeth;
      David","assistantExaminer":["Spooner; Lamont"],"applicationNumber":"12/480556","frontPageStart":1,"frontPageEnd":4,"drawingsStart":5,"drawingsEnd":9,"specificationStart":10,"specificationEnd":15,"claimsStart":15,"claimsEnd":22,"abstractStart":1,"abstractEnd":1,"bibStart":1,"bibEnd":4,"certCorrectionStart":0,"certCorrectionEnd":0,"certReexaminationStart":0,"certReexaminationEnd":0,"supplementalStart":0,"supplementalEnd":0,"ptabStart":0,"ptabEnd":0,"amendStart":0,"amendEnd":0,"searchReportStart":0,"searchReportEnd":0,"pageCount":22,"pageCountDisplay":"22","previouslyViewed":false,"unused":false,"imageLocation":"uspat/US/RE/043/633","imageFileName":"00000001.tif","cpcCodes":null,"queryId":null,"tags":null,"inventorsShort":"Bookman;
      Marc et al.","familyIdentifierCur":22728288,"familyIdentifierCurStr":null,"languageIndicator":"EN","databaseName":"USPT","dwImageDoctypeList":null,"dwImageLocList":null,"dwPageCountList":null,"dwImageDocidList":null,"patentFamilyMembers":null,"patentFamilyCountry":null,"patentFamilySerialNumber":null,"documentIdWithDashesDw":null,"pfPublDate":null,"pfPublDateKwicHits":null,"priorityClaimsDate":null,"priorityClaimsDateKwicHits":null,"pfApplicationSerialNumber":null,"pfApplicationDescriptor":null,"pfLanguage":null,"pfApplicationDate":null,"pfApplicationDateKwicHits":null,"clippedUri":null,"source":null,"documentId":"US
      RE43633 E","derwentAccessionNumber":null,"documentSize":197845,"score":14.104305,"governmentInterest":null,"kindCode":["E"],"urpn":["3872448","4136395","4318184","4384288","4651300","4674065","4689768","4742481","4773009","4817050","4837797","4864501","4868743","4868750","4887212","4893270","4914586","4945476","4958283","4980855","4982344","4994966","5020019","5065315","5088052","5128865","5146439","5146552","5151857","5157606","5204947","5214583","5218697","5222160","5226117","5233513","5241671","5253362","5256067","5267155","5289376","5297249","5303151","5319711","5329446","5331555","5337233","5349368","5351190","5361202","5367621","5375200","5377323","5392386","5404435","5404506","5408655","5416901","5418942","5434974","5438655","5455945","5459860","5491783","5491784","5500859","5506984","5515534","5517409","5530852","5530853","5537132","5537590","5541836","5546447","5546529","5564046","5576955","5581460","5583761","5603025","5606712","5608900","5617488","5629981","5640565","5644740","5646416","5649222","5657259","5659676","5666502","5694523","5708804","5708822","5708825","5724593","5724597","5727129","5729741","5732229","5740252","5745360","5745908","5754847","5754857","5761436","5761656","5761659","5761689","5764906","5778363","5781189","5781900","5781904","5787386","5793972","5794050","5794228","5794259","5799267","5799302","5802559","5805886","5805911","5806079","5815830","5819092","5822539","5822720","5826257","5832496","5835059","5835089","5845238","5855007","5859636","5860073","5862325","5864848","5870702","5870746","5873107","5875443","5875446","5878421","5884247","5884302","5884309","5892919","5893093","5895461","5896321","5896533","5897475","5900004","5905866","5905991","5907838","5913214","5920859","5924090","5926808","5930471","5940843","5946647","5953718","5963205","5963940","5963950","5970505","5974413","5983171","5987403","5987460","5987475","5999938","6006218","6006242","6014677","6021403","6022222","6026088","6026398","6028605","6031537","6038573","6047252","6055531","6061675","6067565","6076088","6085201","6085226","6092074","6094649","6108674","6122647","6126306","6128635","6137911","6151624","6154738","6178434","6182133","6185550","6185576","6233570","6260035","6262730","6272505","6289342","6292768","6308171","6311177","6311194","6323853","6338059","6373502","6438545","6442545","6516321","6519603","6556984","6571241","6601026","6618733","6625581","6629079","6651059","6697824","6732090","6732361","7003522","7032174","7130861","7287218","7496854","RE40731","2002/0035581","2002/0036654","2002/0062353","2002/0065891","2002/0091803","2002/0099730","2002/0184247","2003/0004909","2003/0033290","2003/0154144","2003/0187587","2003/0212527"],"urpnCode":["3872448","4136395","4318184","4384288","4651300","4674065","4689768","4742481","4773009","4817050","4837797","4864501","4868743","4868750","4887212","4893270","4914586","4945476","4958283","4980855","4982344","4994966","5020019","5065315","5088052","5128865","5146439","5146552","5151857","5157606","5204947","5214583","5218697","5222160","5226117","5233513","5241671","5253362","5256067","5267155","5289376","5297249","5303151","5319711","5329446","5331555","5337233","5349368","5351190","5361202","5367621","5375200","5377323","5392386","5404435","5404506","5408655","5416901","5418942","5434974","5438655","5455945","5459860","5491783","5491784","5500859","5506984","5515534","5517409","5530852","5530853","5537132","5537590","5541836","5546447","5546529","5564046","5576955","5581460","5583761","5603025","5606712","5608900","5617488","5629981","5640565","5644740","5646416","5649222","5657259","5659676","5666502","5694523","5708804","5708822","5708825","5724593","5724597","5727129","5729741","5732229","5740252","5745360","5745908","5754847","5754857","5761436","5761656","5761659","5761689","5764906","5778363","5781189","5781900","5781904","5787386","5793972","5794050","5794228","5794259","5799267","5799302","5802559","5805886","5805911","5806079","5815830","5819092","5822539","5822720","5826257","5832496","5835059","5835089","5845238","5855007","5859636","5860073","5862325","5864848","5870702","5870746","5873107","5875443","5875446","5878421","5884247","5884302","5884309","5892919","5893093","5895461","5896321","5896533","5897475","5900004","5905866","5905991","5907838","5913214","5920859","5924090","5926808","5930471","5940843","5946647","5953718","5963205","5963940","5963950","5970505","5974413","5983171","5987403","5987460","5987475","5999938","6006218","6006242","6014677","6021403","6022222","6026088","6026398","6028605","6031537","6038573","6047252","6055531","6061675","6067565","6076088","6085201","6085226","6092074","6094649","6108674","6122647","6126306","6128635","6137911","6151624","6154738","6178434","6182133","6185550","6185576","6233570","6260035","6262730","6272505","6289342","6292768","6308171","6311177","6311194","6323853","6338059","6373502","6438545","6442545","6516321","6519603","6556984","6571241","6601026","6618733","6625581","6629079","6651059","6697824","6732090","6732361","7003522","7032174","7130861","7287218","7496854","RE40731","2002/0035581","2002/0036654","2002/0062353","2002/0065891","2002/0091803","2002/0099730","2002/0184247","2003/0004909","2003/0033290","2003/0154144","2003/0187587","2003/0212527"],"descriptionStart":10,"descriptionEnd":15,"publicationReferenceDocumentNumberOne":"RE043633"}],"qtime":37}'
    headers:
      content-type:
      - application/json
      date:
      - Tue, 07 Nov 2023 19:26:01 GMT
      server-timing:
      - intid;desc=b3bc8dca47ce9873
    http_version: HTTP/2
    status_code: 200
- request:
    body: '{"start": 0, "pageCount": 500, "sort": "date_publ desc", "docFamilyFiltering":
      "familyIdFiltering", "searchType": 1, "familyIdEnglishOnly": true, "familyIdFirstPreferred":
      "US-PGPUB", "familyIdSecondPreferred": "USPAT", "familyIdThirdPreferred": "FPRS",
      "showDocPerFamilyPref": "showEnglish", "queryId": 0, "tagDocSearch": false,
      "query": {"caseId": 23892567, "hl_snippets": "2", "op": "OR", "q": "\"RE43633\".PN.",
      "queryName": "\"RE43633\".PN.", "highlights": "1", "qt": "brs", "spellCheck":
      false, "viewName": "tile", "plurals": true, "britishEquivalents": true, "databaseFilters":
      [{"databaseName": "USPAT", "countryCodes": []}], "searchType": 1, "ignorePersist":
      true, "userEnteredQuery": "\"RE43633\".PN."}}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '713'
      content-type:
      - application/json
      host:
      - ppubs.uspto.gov
      user-agent:
      - Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML,
        like Gecko) Chrome/114.0.0.0 Safari/537.36
      x-requested-with:
      - XMLHttpRequest
    method: POST
    uri: https://ppubs.uspto.gov/dirsearch-public/searches/searchWithBeFamily
  response:
    content: '{"numFound":1,"perPage":500,"page":0,"totalPages":0,"hlSnippets":0,"sort":null,"query":{"id":null,"caseId":23892567,"numResults":1,"ignorePersist":true,"fq":null,"databaseFilters":[{"databaseName":"USPAT","countryCodes":[]}],"q":"\"RE43633\".PN.","queryName":"\"RE43633\".PN.","userEnteredQuery":"\"RE43633\".PN.","viewName":"tile","op":"OR","highlights":"1","plurals":true,"britishEquivalents":true,"searchType":1,"excludeResultsAfter":null,"dateCreated":null,"deleteIn":false,"expand":true,"expandSort":"group_sort_date
      asc, id desc ","expandRows":"100","expandTrackDocScores":true,"expandTrackMaxScore":true,"termGraph":null,"hl":false,"fl":null,"originalQuery":"\"RE43633\".PN.","error":null,"terms":["\"re43633\""],"facets":[],"pNumber":null,"hl_fl":null},"duration":64,"highlightingTime":0,"cursorMarker":"AoJwwPKkx7kCNzIyNzI4Mjg4IVVTLVVTLVJFMDQzNjMz","totalResults":1,"numberOfFamilies":1,"error":null,"patents":[{"guid":"US-RE43633-E","publicationReferenceDocumentNumber":"RE43633","compositeId":"22728288!US-US-RE043633","publicationReferenceDocumentNumber1":"RE043633","datePublishedKwicHits":null,"datePublished":"2012-09-04T00:00:00Z","inventionTitle":"System
      and method for linking streams of multimedia data to reference material for
      display","type":"USPAT","mainClassificationCode":"704/3","applicantName":null,"assigneeName":["Sentius
      International LLC"],"uspcFullClassificationFlattened":"345/157;704/10;704/9;707/999.003;715/255;707/758;704/1;345/160;715/856","ipcCodeFlattened":"G06F17/30;G06F17/28","cpcInventiveFlattened":"G09B19/06;G09B5/065","cpcAdditionalFlattened":null,"applicationFilingDate":["2009-06-08T00:00:00Z"],"applicationFilingDateKwicHits":null,"relatedApplFilingDate":["2005-02-24T00:00:00Z","1994-02-16T00:00:00Z"],"primaryExaminer":"Hudspeth;
      David","assistantExaminer":["Spooner; Lamont"],"applicationNumber":"12/480556","frontPageStart":1,"frontPageEnd":4,"drawingsStart":5,"drawingsEnd":9,"specificationStart":10,"specificationEnd":15,"claimsStart":15,"claimsEnd":22,"abstractStart":1,"abstractEnd":1,"bibStart":1,"bibEnd":4,"certCorrectionStart":0,"certCorrectionEnd":0,"certReexaminationStart":0,"certReexaminationEnd":0,"supplementalStart":0,"supplementalEnd":0,"ptabStart":0,"ptabEnd":0,"amendStart":0,"amendEnd":0,"searchReportStart":0,"searchReportEnd":0,"pageCount":22,"pageCountDisplay":"22","previouslyViewed":false,"unused":false,"imageLocation":"uspat/US/RE/043/633","imageFileName":"00000001.tif","cpcCodes":null,"queryId":null,"tags":null,"inventorsShort":"Bookman;
      Marc et al.","familyIdentifierCur":22728288,"familyIdentifierCurStr":null,"languageIndicator":"EN","databaseName":"USPT","dwImageDoctypeList":null,"dwImageLocList":null,"dwPageCountList":null,"dwImageDocidList":null,"patentFamilyMembers":null,"patentFamilyCountry":null,"patentFamilySerialNumber":null,"documentIdWithDashesDw":null,"pfPublDate":null,"pfPublDateKwicHits":null,"priorityClaimsDate":null,"priorityClaimsDateKwicHits":null,"pfApplicationSerialNumber":null,"pfApplicationDescriptor":null,"pfLanguage":null,"pfApplicationDate":null,"pfApplicationDateKwicHits":null,"clippedUri":null,"source":null,"documentId":"US
      RE43633 E","derwentAccessionNumber":null,"documentSize":197845,"score":14.104305,"governmentInterest":null,"kindCode":["E"],"urpn":["3872448","4136395","4318184","4384288","4651300","4674065","4689768","4742481","4773009","4817050","4837797","4864501","4868743","4868750","4887212","4893270","4914586","4945476","4958283","4980855","4982344","4994966","5020019","5065315","5088052","5128865","5146439","5146552","5151857","5157606","5204947","5214583","5218697","5222160","5226117","5233513","5241671","5253362","5256067","5267155","5289376","5297249","5303151","5319711","5329446","5331555","5337233","5349368","5351190","5361202","5367621","5375200","5377323","5392386","5404435","5404506","5408655","5416901","5418942","5434974","5438655","5455945","5459860","5491783","5491784","5500859","5506984","5515534","5517409","5530852","5530853","5537132","5537590","5541836","5546447","5546529","5564046","5576955","5581460","5583761","5603025","5606712","5608900","5617488","5629981","5640565","5644740","5646416","5649222","5657259","5659676","5666502","5694523","5708804","5708822","5708825","5724593","5724597","5727129","5729741","5732229","5740252","5745360","5745908","5754847","5754857","5761436","5761656","5761659","5761689","5764906","5778363","5781189","5781900","5781904","5787386","5793972","5794050","5794228","5794259","5799267","5799302","5802559","5805886","5805911","5806079","5815830","5819092","5822539","5822720","5826257","5832496","5835059","5835089","5845238","5855007","5859636","5860073","5862325","5864848","5870702","5870746","5873107","5875443","5875446","5878421","5884247","5884302","5884309","5892919","5893093","5895461","5896321","5896533","5897475","5900004","5905866","5905991","5907838","5913214","5920859","5924090","5926808","5930471","5940843","5946647","5953718","5963205","5963940","5963950","5970505","5974413","5983171","5987403","5987460","5987475","5999938","6006218","6006242","6014677","6021403","6022222","6026088","6026398","6028605","6031537","6038573","6047252","6055531","6061675","6067565","6076088","6085201","6085226","6092074","6094649","6108674","6122647","6126306","6128635","6137911","6151624","6154738","6178434","6182133","6185550","6185576","6233570","6260035","6262730","6272505","6289342","6292768","6308171","6311177","6311194","6323853","6338059","6373502","6438545","6442545","6516321","6519603","6556984","6571241","6601026","6618733","6625581","6629079","6651059","6697824","6732090","6732361","7003522","7032174","7130861","7287218","7496854","RE40731","2002/0035581","2002/0036654","2002/0062353","2002/0065891","2002/0091803","2002/0099730","2002/0184247","2003/0004909","2003/0033290","2003/0154144","2003/0187587","2003/0212527"],"urpnCode":["3872448","4136395","4318184","4384288","4651300","4674065","4689768","4742481","4773009","4817050","4837797","4864501","4868743","4868750","4887212","4893270","4914586","4945476","4958283","4980855","4982344","4994966","5020019","5065315","5088052","5128865","5146439","5146552","5151857","5157606","5204947","5214583","5218697","5222160","5226117","5233513","5241671","5253362","5256067","5267155","5289376","5297249","5303151","5319711","5329446","5331555","5337233","5349368","5351190","5361202","5367621","5375200","5377323","5392386","5404435","5404506","5408655","5416901","5418942","5434974","5438655","5455945","5459860","5491783","5491784","5500859","5506984","5515534","5517409","5530852","5530853","5537132","5537590","5541836","5546447","5546529","5564046","5576955","5581460","5583761","5603025","5606712","5608900","5617488","5629981","5640565","5644740","5646416","5649222","5657259","5659676","5666502","5694523","5708804","5708822","5708825","5724593","5724597","5727129","5729741","5732229","5740252","5745360","5745908","5754847","5754857","5761436","5761656","5761659","5761689","5764906","5778363","5781189","5781900","5781904","5787386","5793972","5794050","5794228","5794259","5799267","5799302","5802559","5805886","5805911","5806079","5815830","5819092","5822539","5822720","5826257","5832496","5835059","5835089","5845238","5855007","5859636","5860073","5862325","5864848","5870702","5870746","5873107","5875443","5875446","5878421","5884247","5884302","5884309","5892919","5893093","5895461","5896321","5896533","5897475","5900004","5905866","5905991","5907838","5913214","5920859","5924090","5926808","5930471","5940843","5946647","5953718","5963205","5963940","5963950","5970505","5974413","5983171","5987403","5987460","5987475","5999938","6006218","6006242","6014677","6021403","6022222","6026088","6026398","6028605","6031537","6038573","6047252","6055531","6061675","6067565","6076088","6085201","6085226","6092074","6094649","6108674","6122647","6126306","6128635","6137911","6151624","6154738","6178434","6182133","6185550","6185576","6233570","6260035","6262730","6272505","6289342","6292768","6308171","6311177","6311194","6323853","6338059","6373502","6438545","6442545","6516321","6519603","6556984","6571241","6601026","6618733","6625581","6629079","6651059","6697824","6732090","6732361","7003522","7032174","7130861","7287218","7496854","RE40731","2002/0035581","2002/0036654","2002/0062353","2002/0065891","2002/0091803","2002/0099730","2002/0184247","2003/0004909","2003/0033290","2003/0154144","2003/0187587","2003/0212527"],"descriptionStart":10,"descriptionEnd":15,"publicationReferenceDocumentNumberOne":"RE043633"}],"qtime":37}'
    headers:
      content-type:
      - application/json
      date:
      - Tue, 07 Nov 2023 19:26:01 GMT
      server-timing:
      - intid;desc=29298b01dc13aab1
    http_version: HTTP/2
    status_code: 200
- request:
    body: '{"start": 0, "pageCount": 500, "sort": "date_publ desc", "docFamilyFiltering":
      "familyIdFiltering", "searchType": 1, "familyIdEnglishOnly": true, "familyIdFirstPreferred":
      "US-PGPUB", "familyIdSecondPreferred": "USPAT", "familyIdThirdPreferred": "FPRS",
      "showDocPerFamilyPref": "showEnglish", "queryId": 0, "tagDocSearch": false,
      "query": {"caseId": 23892567, "hl_snippets": "2", "op": "OR", "q": "\"RE43633\".PN.",
      "queryName": "\"RE43633\".PN.", "highlights": "1", "qt": "brs", "spellCheck":
      false, "viewName": "tile", "plurals": true, "britishEquivalents": true, "databaseFilters":
      [{"databaseName": "USPAT", "countryCodes": []}], "searchType": 1, "ignorePersist":
      true, "userEnteredQuery": "\"RE43633\".PN."}}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '713'
      content-type:
      - application/json
      host:
      - ppubs.uspto.gov
      user-agent:
      - Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML,
        like Gecko) Chrome/114.0.0.0 Safari/537.36
      x-requested-with:
      - XMLHttpRequest
    method: POST
    uri: https://ppubs.uspto.gov/dirsearch-public/searches/searchWithBeFamily
  response:
    content: '{"numFound":1,"perPage":500,"page":0,"totalPages":0,"hlSnippets":0,"sort":null,"query":{"id":null,"caseId":23892567,"numResults":1,"ignorePersist":true,"fq":null,"databaseFilters":[{"databaseName":"USPAT","countryCodes":[]}],"q":"\"RE43633\".PN.","queryName":"\"RE43633\".PN.","userEnteredQuery":"\"RE43633\".PN.","viewName":"tile","op":"OR","highlights":"1","plurals":true,"britishEquivalents":true,"searchType":1,"excludeResultsAfter":null,"dateCreated":null,"deleteIn":false,"expand":true,"expandSort":"group_sort_date
      asc, id desc ","expandRows":"100","expandTrackDocScores":true,"expandTrackMaxScore":true,"termGraph":null,"hl":false,"fl":null,"originalQuery":"\"RE43633\".PN.","error":null,"terms":["\"re43633\""],"facets":[],"pNumber":null,"hl_fl":null},"duration":57,"highlightingTime":0,"cursorMarker":"AoJwwPKkx7kCNzIyNzI4Mjg4IVVTLVVTLVJFMDQzNjMz","totalResults":1,"numberOfFamilies":1,"error":null,"patents":[{"guid":"US-RE43633-E","publicationReferenceDocumentNumber":"RE43633","compositeId":"22728288!US-US-RE043633","publicationReferenceDocumentNumber1":"RE043633","datePublishedKwicHits":null,"datePublished":"2012-09-04T00:00:00Z","inventionTitle":"System
      and method for linking streams of multimedia data to reference material for
      display","type":"USPAT","mainClassificationCode":"704/3","applicantName":null,"assigneeName":["Sentius
      International LLC"],"uspcFullClassificationFlattened":"345/157;704/10;704/9;707/999.003;715/255;707/758;704/1;345/160;715/856","ipcCodeFlattened":"G06F17/30;G06F17/28","cpcInventiveFlattened":"G09B19/06;G09B5/065","cpcAdditionalFlattened":null,"applicationFilingDate":["2009-06-08T00:00:00Z"],"applicationFilingDateKwicHits":null,"relatedApplFilingDate":["2005-02-24T00:00:00Z","1994-02-16T00:00:00Z"],"primaryExaminer":"Hudspeth;
      David","assistantExaminer":["Spooner; Lamont"],"applicationNumber":"12/480556","frontPageStart":1,"frontPageEnd":4,"drawingsStart":5,"drawingsEnd":9,"specificationStart":10,"specificationEnd":15,"claimsStart":15,"claimsEnd":22,"abstractStart":1,"abstractEnd":1,"bibStart":1,"bibEnd":4,"certCorrectionStart":0,"certCorrectionEnd":0,"certReexaminationStart":0,"certReexaminationEnd":0,"supplementalStart":0,"supplementalEnd":0,"ptabStart":0,"ptabEnd":0,"amendStart":0,"amendEnd":0,"searchReportStart":0,"searchReportEnd":0,"pageCount":22,"pageCountDisplay":"22","previouslyViewed":false,"unused":false,"imageLocation":"uspat/US/RE/043/633","imageFileName":"00000001.tif","cpcCodes":null,"queryId":null,"tags":null,"inventorsShort":"Bookman;
      Marc et al.","familyIdentifierCur":22728288,"familyIdentifierCurStr":null,"languageIndicator":"EN","databaseName":"USPT","dwImageDoctypeList":null,"dwImageLocList":null,"dwPageCountList":null,"dwImageDocidList":null,"patentFamilyMembers":null,"patentFamilyCountry":null,"patentFamilySerialNumber":null,"documentIdWithDashesDw":null,"pfPublDate":null,"pfPublDateKwicHits":null,"priorityClaimsDate":null,"priorityClaimsDateKwicHits":null,"pfApplicationSerialNumber":null,"pfApplicationDescriptor":null,"pfLanguage":null,"pfApplicationDate":null,"pfApplicationDateKwicHits":null,"clippedUri":null,"source":null,"documentId":"US
      RE43633 E","derwentAccessionNumber":null,"documentSize":197845,"score":14.113765,"governmentInterest":null,"kindCode":["E"],"urpn":["3872448","4136395","4318184","4384288","4651300","4674065","4689768","4742481","4773009","4817050","4837797","4864501","4868743","4868750","4887212","4893270","4914586","4945476","4958283","4980855","4982344","4994966","5020019","5065315","5088052","5128865","5146439","5146552","5151857","5157606","5204947","5214583","5218697","5222160","5226117","5233513","5241671","5253362","5256067","5267155","5289376","5297249","5303151","5319711","5329446","5331555","5337233","5349368","5351190","5361202","5367621","5375200","5377323","5392386","5404435","5404506","5408655","5416901","5418942","5434974","5438655","5455945","5459860","5491783","5491784","5500859","5506984","5515534","5517409","5530852","5530853","5537132","5537590","5541836","5546447","5546529","5564046","5576955","5581460","5583761","5603025","5606712","5608900","5617488","5629981","5640565","5644740","5646416","5649222","5657259","5659676","5666502","5694523","5708804","5708822","5708825","5724593","5724597","5727129","5729741","5732229","5740252","5745360","5745908","5754847","5754857","5761436","5761656","5761659","5761689","5764906","5778363","5781189","5781900","5781904","5787386","5793972","5794050","5794228","5794259","5799267","5799302","5802559","5805886","5805911","5806079","5815830","5819092","5822539","5822720","5826257","5832496","5835059","5835089","5845238","5855007","5859636","5860073","5862325","5864848","5870702","5870746","5873107","5875443","5875446","5878421","5884247","5884302","5884309","5892919","5893093","5895461","5896321","5896533","5897475","5900004","5905866","5905991","5907838","5913214","5920859","5924090","5926808","5930471","5940843","5946647","5953718","5963205","5963940","5963950","5970505","5974413","5983171","5987403","5987460","5987475","5999938","6006218","6006242","6014677","6021403","6022222","6026088","6026398","6028605","6031537","6038573","6047252","6055531","6061675","6067565","6076088","6085201","6085226","6092074","6094649","6108674","6122647","6126306","6128635","6137911","6151624","6154738","6178434","6182133","6185550","6185576","6233570","6260035","6262730","6272505","6289342","6292768","6308171","6311177","6311194","6323853","6338059","6373502","6438545","6442545","6516321","6519603","6556984","6571241","6601026","6618733","6625581","6629079","6651059","6697824","6732090","6732361","7003522","7032174","7130861","7287218","7496854","RE40731","2002/0035581","2002/0036654","2002/0062353","2002/0065891","2002/0091803","2002/0099730","2002/0184247","2003/0004909","2003/0033290","2003/0154144","2003/0187587","2003/0212527"],"urpnCode":["3872448","4136395","4318184","4384288","4651300","4674065","4689768","4742481","4773009","4817050","4837797","4864501","4868743","4868750","4887212","4893270","4914586","4945476","4958283","4980855","4982344","4994966","5020019","5065315","5088052","5128865","5146439","5146552","5151857","5157606","5204947","5214583","5218697","5222160","5226117","5233513","5241671","5253362","5256067","5267155","5289376","5297249","5303151","5319711","5329446","5331555","5337233","5349368","5351190","5361202","5367621","5375200","5377323","5392386","5404435","5404506","5408655","5416901","5418942","5434974","5438655","5455945","5459860","5491783","5491784","5500859","5506984","5515534","5517409","5530852","5530853","5537132","5537590","5541836","5546447","5546529","5564046","5576955","5581460","5583761","5603025","5606712","5608900","5617488","5629981","5640565","5644740","5646416","5649222","5657259","5659676","5666502","5694523","5708804","5708822","5708825","5724593","5724597","5727129","5729741","5732229","5740252","5745360","5745908","5754847","5754857","5761436","5761656","5761659","5761689","5764906","5778363","5781189","5781900","5781904","5787386","5793972","5794050","5794228","5794259","5799267","5799302","5802559","5805886","5805911","5806079","5815830","5819092","5822539","5822720","5826257","5832496","5835059","5835089","5845238","5855007","5859636","5860073","5862325","5864848","5870702","5870746","5873107","5875443","5875446","5878421","5884247","5884302","5884309","5892919","5893093","5895461","5896321","5896533","5897475","5900004","5905866","5905991","5907838","5913214","5920859","5924090","5926808","5930471","5940843","5946647","5953718","5963205","5963940","5963950","5970505","5974413","5983171","5987403","5987460","5987475","5999938","6006218","6006242","6014677","6021403","6022222","6026088","6026398","6028605","6031537","6038573","6047252","6055531","6061675","6067565","6076088","6085201","6085226","6092074","6094649","6108674","6122647","6126306","6128635","6137911","6151624","6154738","6178434","6182133","6185550","6185576","6233570","6260035","6262730","6272505","6289342","6292768","6308171","6311177","6311194","6323853","6338059","6373502","6438545","6442545","6516321","6519603","6556984","6571241","6601026","6618733","6625581","6629079","6651059","6697824","6732090","6732361","7003522","7032174","7130861","7287218","7496854","RE40731","2002/0035581","2002/0036654","2002/0062353","2002/0065891","2002/0091803","2002/0099730","2002/0184247","2003/0004909","2003/0033290","2003/0154144","2003/0187587","2003/0212527"],"descriptionStart":10,"descriptionEnd":15,"publicationReferenceDocumentNumberOne":"RE043633"}],"qtime":33}'
    headers:
      content-type:
      - application/json
      date:
      - Tue, 07 Nov 2023 19:26:01 GMT
      server-timing:
      - intid;desc=1324ec9bcb9a59b3
    http_version: HTTP/2
    status_code: 200
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - ppubs.uspto.gov
      user-agent:
      - Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML,
        like Gecko) Chrome/114.0.0.0 Safari/537.36
      x-requested-with:
      - XMLHttpRequest
    method: GET
    uri: https://ppubs.uspto.gov/dirsearch-public/patents/US-RE43633-E/highlight?queryId=1&source=USPAT&includeSections=true&uniqueId=
  response:
    content: '{"guid":"US-RE43633-E","publicationReferenceDocumentNumber":"RE43633","compositeId":"22728288!US-US-RE043633","publicationReferenceDocumentNumber1":"RE043633","datePublishedKwicHits":null,"datePublished":"2012-09-04T00:00:00Z","inventionTitle":"System
      and method for linking streams of multimedia data to reference material for
      display","type":"USPAT","mainClassificationCode":"704/3","applicantName":null,"assigneeName":["Sentius
      International LLC"],"uspcFullClassificationFlattened":"345/157;704/10;704/9;707/999.003;715/255;707/758;704/1;345/160;715/856","ipcCodeFlattened":"G06F17/30;G06F17/28","cpcInventiveFlattened":"G09B19/06;G09B5/065","cpcAdditionalFlattened":null,"applicationFilingDate":["2009-06-08T00:00:00Z"],"applicationFilingDateKwicHits":null,"relatedApplFilingDate":["2005-02-24T00:00:00Z","1994-02-16T00:00:00Z"],"primaryExaminer":"Hudspeth;
      David","assistantExaminer":["Spooner; Lamont"],"applicationNumber":"12/480556","frontPageStart":1,"frontPageEnd":4,"drawingsStart":5,"drawingsEnd":9,"specificationStart":10,"specificationEnd":15,"claimsStart":15,"claimsEnd":22,"abstractStart":1,"abstractEnd":1,"bibStart":1,"bibEnd":4,"certCorrectionStart":0,"certCorrectionEnd":0,"certReexaminationStart":0,"certReexaminationEnd":0,"supplementalStart":0,"supplementalEnd":0,"ptabStart":0,"ptabEnd":0,"amendStart":0,"amendEnd":0,"searchReportStart":0,"searchReportEnd":0,"pageCount":22,"pageCountDisplay":"22","previouslyViewed":false,"unused":false,"imageLocation":"uspat/US/RE/043/633","imageFileName":"00000001.tif","cpcCodes":null,"queryId":1,"tags":null,"inventorsShort":"Bookman;
      Marc et al.","familyIdentifierCur":22728288,"familyIdentifierCurStr":"22728288","languageIndicator":"EN","databaseName":"USPT","dwImageDoctypeList":null,"dwImageLocList":null,"dwPageCountList":null,"dwImageDocidList":null,"patentFamilyMembers":null,"patentFamilyCountry":null,"patentFamilySerialNumber":null,"documentIdWithDashesDw":null,"pfPublDate":null,"pfPublDateKwicHits":null,"priorityClaimsDate":null,"priorityClaimsDateKwicHits":null,"pfApplicationSerialNumber":null,"pfApplicationDescriptor":null,"pfLanguage":null,"pfApplicationDate":null,"pfApplicationDateKwicHits":null,"clippedUri":null,"source":null,"documentId":"<span
      term=\"usre43633e\" class=\"highlight18\">US RE43633 E</span>","derwentAccessionNumber":null,"documentSize":197845,"score":0.0,"governmentInterest":null,"kindCode":["E"],"urpn":["3872448","4136395","4318184","4384288","4651300","4674065","4689768","4742481","4773009","4817050","4837797","4864501","4868743","4868750","4887212","4893270","4914586","4945476","4958283","4980855","4982344","4994966","5020019","5065315","5088052","5128865","5146439","5146552","5151857","5157606","5204947","5214583","5218697","5222160","5226117","5233513","5241671","5253362","5256067","5267155","5289376","5297249","5303151","5319711","5329446","5331555","5337233","5349368","5351190","5361202","5367621","5375200","5377323","5392386","5404435","5404506","5408655","5416901","5418942","5434974","5438655","5455945","5459860","5491783","5491784","5500859","5506984","5515534","5517409","5530852","5530853","5537132","5537590","5541836","5546447","5546529","5564046","5576955","5581460","5583761","5603025","5606712","5608900","5617488","5629981","5640565","5644740","5646416","5649222","5657259","5659676","5666502","5694523","5708804","5708822","5708825","5724593","5724597","5727129","5729741","5732229","5740252","5745360","5745908","5754847","5754857","5761436","5761656","5761659","5761689","5764906","5778363","5781189","5781900","5781904","5787386","5793972","5794050","5794228","5794259","5799267","5799302","5802559","5805886","5805911","5806079","5815830","5819092","5822539","5822720","5826257","5832496","5835059","5835089","5845238","5855007","5859636","5860073","5862325","5864848","5870702","5870746","5873107","5875443","5875446","5878421","5884247","5884302","5884309","5892919","5893093","5895461","5896321","5896533","5897475","5900004","5905866","5905991","5907838","5913214","5920859","5924090","5926808","5930471","5940843","5946647","5953718","5963205","5963940","5963950","5970505","5974413","5983171","5987403","5987460","5987475","5999938","6006218","6006242","6014677","6021403","6022222","6026088","6026398","6028605","6031537","6038573","6047252","6055531","6061675","6067565","6076088","6085201","6085226","6092074","6094649","6108674","6122647","6126306","6128635","6137911","6151624","6154738","6178434","6182133","6185550","6185576","6233570","6260035","6262730","6272505","6289342","6292768","6308171","6311177","6311194","6323853","6338059","6373502","6438545","6442545","6516321","6519603","6556984","6571241","6601026","6618733","6625581","6629079","6651059","6697824","6732090","6732361","7003522","7032174","7130861","7287218","7496854","RE40731","2002/0035581","2002/0036654","2002/0062353","2002/0065891","2002/0091803","2002/0099730","2002/0184247","2003/0004909","2003/0033290","2003/0154144","2003/0187587","2003/0212527"],"urpnCode":["3872448","4136395","4318184","4384288","4651300","4674065","4689768","4742481","4773009","4817050","4837797","4864501","4868743","4868750","4887212","4893270","4914586","4945476","4958283","4980855","4982344","4994966","5020019","5065315","5088052","5128865","5146439","5146552","5151857","5157606","5204947","5214583","5218697","5222160","5226117","5233513","5241671","5253362","5256067","5267155","5289376","5297249","5303151","5319711","5329446","5331555","5337233","5349368","5351190","5361202","5367621","5375200","5377323","5392386","5404435","5404506","5408655","5416901","5418942","5434974","5438655","5455945","5459860","5491783","5491784","5500859","5506984","5515534","5517409","5530852","5530853","5537132","5537590","5541836","5546447","5546529","5564046","5576955","5581460","5583761","5603025","5606712","5608900","5617488","5629981","5640565","5644740","5646416","5649222","5657259","5659676","5666502","5694523","5708804","5708822","5708825","5724593","5724597","5727129","5729741","5732229","5740252","5745360","5745908","5754847","5754857","5761436","5761656","5761659","5761689","5764906","5778363","5781189","5781900","5781904","5787386","5793972","5794050","5794228","5794259","5799267","5799302","5802559","5805886","5805911","5806079","5815830","5819092","5822539","5822720","5826257","5832496","5835059","5835089","5845238","5855007","5859636","5860073","5862325","5864848","5870702","5870746","5873107","5875443","5875446","5878421","5884247","5884302","5884309","5892919","5893093","5895461","5896321","5896533","5897475","5900004","5905866","5905991","5907838","5913214","5920859","5924090","5926808","5930471","5940843","5946647","5953718","5963205","5963940","5963950","5970505","5974413","5983171","5987403","5987460","5987475","5999938","6006218","6006242","6014677","6021403","6022222","6026088","6026398","6028605","6031537","6038573","6047252","6055531","6061675","6067565","6076088","6085201","6085226","6092074","6094649","6108674","6122647","6126306","6128635","6137911","6151624","6154738","6178434","6182133","6185550","6185576","6233570","6260035","6262730","6272505","6289342","6292768","6308171","6311177","6311194","6323853","6338059","6373502","6438545","6442545","6516321","6519603","6556984","6571241","6601026","6618733","6625581","6629079","6651059","6697824","6732090","6732361","7003522","7032174","7130861","7287218","7496854","RE40731","2002/0035581","2002/0036654","2002/0062353","2002/0065891","2002/0091803","2002/0099730","2002/0184247","2003/0004909","2003/0033290","2003/0154144","2003/0187587","2003/0212527"],"abstractedPatentNumber":null,"assigneeCity":["McLean"],"assigneePostalCode":["N/A"],"assigneeState":["VA"],"assigneeTypeCode":["02"],"curIntlPatentClassificationPrimary":["G06F17/30
      20060101"],"curIntlPatentClassificationPrimaryDateKwicHits":null,"designatedStates":null,"examinerGroup":"2626","issuedUsCrossRefClassification":["345/157","345/160","704/1","704/9","704/10","715/856","715/255","707/999.003","707/758"],"jpoFtermCurrent":null,"languageOfSpecification":null,"chosenDrawingsReference":null,"derwentClass":null,"inventionTitleHighlights":null,"cpcOrigInventiveClassificationHighlights":null,"cpcInventiveDateKwicHits":null,"cpcOrigAdditionalClassification":null,"cpcAdditionalDateKwicHits":null,"curIntlPatentClssficationSecHighlights":null,"fieldOfSearchClassSubclassHighlights":["707/706-708","707/758","707/999.003","704/1","704/9","704/10","715/255","715/856","345/157","345/160"],"cpcCombinationSetsCurHighlights":null,"applicantCountry":null,"applicantCity":null,"applicantState":null,"applicantZipCode":null,"applicantAuthorityType":null,"applicantDescriptiveText":null,"applicationSerialNumber":["480556"],"inventorCity":["Palo
      Alto","Mountain View"],"inventorState":["CA","CA"],"inventorPostalCode":["N/A","N/A"],"standardTitleTermsHighlights":null,"primaryExaminerHighlights":"Hudspeth;
      David","continuityData":["reissue parent-doc US 08676890 19960708 GRANTED US
      5822720 19981013 child-doc US 12480556\n<br />continuation parent-doc US 11064519
      20050224 US Re. 40731 child-doc US 08676890\n<br />continuation parent-doc US
      08197157 19940216 ABANDONED child-doc US 11064519\n<br />"],"inventors":null,"uspcFullClassification":null,"uspcCodeFmtFlattened":null,"ipcCode":null,"applicationNumberHighlights":["12/480556"],"dateProduced":"2012-08-15T00:00:00Z","auxFamilyMembersGroupTempPlaceHolder":null,"priorityCountryCode":null,"cpcCurAdditionalClassification":null,"internationalClassificationMain":null,"internationalClassificationSecondary":null,"internationalClassificationInformational":null,"europeanClassification":null,"europeanClassificationMain":null,"europeanClassificationSecondary":null,"lanuageIndicator":null,"intlPubClassificationPrimary":["G06F17/30
      20060101 G06F017/30"],"intlPubClassificationPrimaryDateKwicHits":null,"intlPubClassificationSecondary":["G06F17/28
      20060101 G06F017/28"],"intlPubClassificationSecondaryDateKwicHits":null,"publicationDate":null,"derwentWeekInt":0,"derwentWeek":null,"currentUsOriginalClassification":"704/3","currentUsCrossReferenceClassification":["345/157","704/10","704/9","707/999.003","715/255","707/758","704/1","345/160","715/856"],"locarnoClassification":null,"equivalentAbstractText":null,"hagueIntlRegistrationNumber":null,"hagueIntlFilingDate":null,"hagueIntlFilingDateKwicHits":null,"hagueIntlRegistrationDate":null,"hagueIntlRegistrationDateKwicHits":null,"hagueIntlRegistrationPubDate":null,"hagueIntlRegistrationPubDateKwicHits":null,"curIntlPatentClassificationNoninvention":null,"curIntlPatentClassificationNoninventionDateKwicHits":null,"curIntlPatentClassificationSecondary":["G06F17/28
      20060101"],"curIntlPatentClassificationSecondaryDateKwicHits":null,"abstractHtml":"A
      system for indexing displayed elements that is useful for accessing and understanding
      new or difficult materials, in which a user highlights unknown words or characters
      or other displayed elements encountered while viewing displayed materials. In
      a language learning application, the system displays the meaning of a word in
      context; and the user may include the word in a personal vocabulary to build
      a database of words and phrases. In a Japanese language application, one or
      more Japanese language books are read on an electronic display. Readings (`yomi`)
      for all words are readily viewable for any selected word or phrase, as well
      as an English reference to the selected word or phrase. Extensive notes are
      provided for difficult phrases and words not normally found in a dictionary.
      A unique indexing scheme allows word-by-word access to any of several external
      multi-media references.","descriptionHtml":"(1) BRIEF DESCRIPTION OF THE DRAWINGS<br
      />(2)  FIG. 1 is a block schematic diagram of a language learning system according
      to the invention;<br />(3)  FIG. 2 is a flow diagram in which the mechanism
      for indexing and linking text to external references is shown according to the
      invention;<br />(4)  FIG. 3 is a screen display showing a highlighted Japanese
      word and a pop-up menu, including an English reference to the Japanese word,
      according to the invention;<br />(5)  FIG. 4 is a screen display showing a highlighted
      Japanese word and a pop-up menu, including Japanese language annotations of
      the Japanese word, according to the invention; and<br />(6)  FIG. 5 is a screen
      display showing a Japanese word listed in a personal dictionary, as well as
      a word control palette, according to the invention.<br />(7) DETAILED DESCRIPTION
      OF THE INVENTION<br />(8)  The invention provides a system that is designed
      to enhance and improve the way one reads or learns to read a difficult text,
      such as a foreign language, especially a language based upon an ideographic
      alphabet, such as Kanji which is used in the Japanese language. The text may
      be any of actual text based material, or audio, video, or graphic based information.
      In the language learning application, the system is modeled on the process by
      which the foreign language is read and addresses the problems most persons face
      when reading a language that is different from their own.<br />(9)  The exemplary
      embodiment of the invention is based upon two powerful functional modules that
      provide a comprehensive approach to reading and learning a foreign language,
      such as Japanese. The first module is an electronic viewer that gives the user
      access to reference information on each word in the electronic text at a word
      by word level. The second module is a relational database that allows a user
      to create word lists with practically no limit in size. The two modules are
      integrated to provide the user with everything needed to read the foreign language
      quickly and enjoyably, as well as to build their own individual vocabulary.<br
      />(10)  FIG. 1 is a block schematic diagram of an exemplary embodiment of the
      invention that implements a language learning system. An electronic book and/or
      a multi-media source material is provided as a teaching resource. A text file
      10 and/or a multimedia source 14, consisting of an audio/video file 11 and synchronized
      text 13, which may include sound, images, and/or video is edited during construction
      of a linked text database by a visual editor 19 that used to build a wordified
      database 20. The database 20 sources a grammar parser 23 and a link engine 22
      that builds an index 21 which, in turn, locates each textual and audio/video
      reference in the source material. The index provides a location for each reference
      in a database 12 that includes a relational database engine 15, and linkable
      entities, such as text references 16, audio references 17, graphic references
      18, and the like.<br />(11)  The link engine 22 outputs the selected text to
      a word list 28 derived from the input text file 10 and/or audio/video information
      14, and also outputs the reference information 24, consisting of linkable entities
      25, 26, 27, which are derived from the indexed database 12. The indexor/viewer
      29 creates a multi-media resource 30, such as a file 33 that was processed as
      described above to produce a data resource 34, an offset index 35, and linked
      entities 36 to the data resource for access by the user.<br />(12)  A user interface
      32 to the system includes an electronic viewer 43 that runs along with the system
      application program 42 and provides the following functional elements: index
      management 37, user display 38, a table of contents 39, a pop-up display 40,
      and a personal dictionary 41.<br />(13)  The electronic viewer module is used
      to view and read the electronic books provided with the language learning system.
      The module includes the following features: 1. One-click, pop-up information
      for all words containing foreign language words; 2. A word display palette;
      3. A contents menu for each book; 4. Search functions; 5. Selectable browse
      and edit modes; and 6. The ability to copy words and associated information
      into personal dictionary.<br />(14)  The personal dictionary is a relational
      database that is optimized to manage and study words. Unlike electronic dictionaries,
      where only the word entries of the dictionary are searchable, the personal dictionary
      of the system herein allows one to search on each of eight or more keys associated
      with a word.<br />(15)  The following functions are supported by the personal
      dictionary: 1. Display of words in an easy to read, easy to access format; 2.
      Full relational database capabilities for the following: the word, the pronunciation,
      English reference, notes, category, source, priority, and review date; 3. Search
      capabilities for any item; 4. Capabilities to store an unlimited number of words;
      5. A flash word feature to allow self-testing in sorted or random order; and
      6. Capabilities to review words sorted by any word key.<br />(16)  The personal
      dictionary also allows the user to enter words from other sources that are currently
      in paper or other electronic formats. For example, a user can copy all the words
      that they have in paper format from study lists and notes. With this feature,
      a student can have all of his study materials in one easy to access database.
      Users can also import and export data in a text format supported by standard
      word processor and spreadsheet programs.<br />(17)  The exemplary personal dictionary
      includes a base 500-word vocabulary list designed for the beginning student.
      A variety of words are included related to such general topics as: foods and
      drink, family, health, the body, commuting and transportation, environment,
      economics, finance, politics, companies, industries, computers, sports, and
      the language itself.<br />(18)  The system includes one or more electronic books.
      The words in each book is fully supported with readings, English references,
      and hypernotes. In the exemplary embodiment of the invention there are typically
      over 10,000 words, as well as over 1,000 notes presented in an easy to read,
      easy to memorize format.<br />(19)  The English reference feature of the system
      provides basic information to help users understand the word in its context.
      For each word, a generalized definition of the word is provided. The pop-up
      fields are used to give the user a quick reference to the word and to allow
      the user to continue reading or reviewing the text.<br />(20)  Current electronic
      book formats provide simple hyperlinks in what is termed hypertext or multimedia.
      Hyperlinks to date have been simple pointers that directly link text with other
      text, graphics, or sound within the text file itself. For reference materials,
      such as electronic encyclopedias, and dictionaries, hyperlinks provide a quick
      and easy way to find related material to a topic or subject. However, these
      links must be hard coded and are therefore cumbersome to author. The format
      of the system herein described provides a new means of relating text, pictures,
      and/or video with information to enrich and expand the impact of every element
      in a text, picture, or video. This format differs from current electronic books
      which only link text with other parts of text or content.<br />(21)  In the
      new format of the present system, every word or sound, for example, can be linked
      to information not contained within the text using an indexing method that maps
      a single word or phrase to a table that contains external reference material.
      This reference can be in the form .[.or.]. .Iadd.of .Iaddend.text, graphics,
      images, movies, and/or sound. Thus, the resource materials, such as the text,
      remains unaltered and therefore compact in terms of file size. Thus, the resource
      materials, for example the text, takes up less disk space and runs faster.<br
      />(22)  FIG. 2 is a flow diagram in which the mechanism for indexing and linking
      text to external references is shown according to the invention. To find a reference
      to a particular word or other selected entry displayed on the screen, the user
      clicks the text that is viewed with a pointing device, such as a mouse (200).
      The click position is determined and used to calculate an offset value within
      the text (200). In the example shown in FIG. 2, the user clicks at a particular
      location, e.g. horizontal and vertical coordinates 100 and 75, respectively,
      and an offset value of 25 is returned. The offset value is compared to the start
      and end position indices stored in a look-up table (201, 202). The link between
      the selected text and the external reference is resolved (203), and the external
      reference is retrieved and displayed to the user (204). In the example of FIG.
      2 an offset of 25 is located at the look-up table location having a start point
      of 20 and an end point of 27 and is linked to text located at position 200.
      As can be seen from the look-up table (202), the link may be to text, sound,
      pictures, and video. In the example, the text linkage is to the English language
      word &quot;Japanese economy&quot;.<br />(23)  The actual indexing process is
      completed in several steps, including word cuts, linking, and compilation.<br
      />(24)  Word Cuts<br />(25)  The word cutting process is accomplished using
      a simple visual editor, for example a point and click system using a pointing
      device, such as a mouse. The process divides the text into the individual components
      of text that are linked with the additional reference material. The original
      text is provided by a publisher in electronic form in a raw binary text format
      (e.g. an ASCII text file or other word processor file). This text is then divided
      up into the component word or phrases in preparation for the next step.<br />(26)  Linking<br
      />(27)  The linking process takes the text after the word cut process and links
      it to an external reference. The database 20 sources a grammar parser 23 and
      a link engine 22 that builds an index 21 which, in turn, locates each textual
      and audio/video reference in the source material. In the case of language learning,
      the component words and phrases are linked to a foreign language dictionary.
      In other cases, links may be made to other reference materials, such as graphics
      and/or sound.<br />(28)  Compilation<br />(29)  After linking, the text and
      references are compiled. During compilation, the cut text is reassembled to
      create an image of the text that the end user sees. At this point additional
      formatting may be applied to the text for final display. Indices of the component
      words and phrases are built with links to the reference material and duplicate
      references are consolidated to conserve memory and storage requirements.<br
      />(30)  A key feature of the system format is the method by which the original
      book text is indexed and linked with the external references. During the compile
      process an image of the text is created. When the image is created, the cuts
      are indexed based upon the position offset from the beginning of the text. The
      start and end points of the cut text are recorded in a look-up table along with
      the links to external references. The number and type of links for any component
      is dynamic. This means that a single entry could have several different references
      attached to it, each containing different forms of data.<br />(31)  The user
      interacts with the electronic book using a pointing device. When the user &quot;clicks&quot;
      within the text image, the location of the pointer is determined. The location
      is converted into a position offset from the beginning of the text and used
      to determine which component word or phrase was selected. The process involves
      comparing the offset with the start and end values stored in the look-up table
      as discussed above in connection with FIG. 2. When the offset value falls between
      a component''s start and end points, a match is made and the external references
      can be resolved.<br />(32)  English Reference<br />(33)  FIG. 3 is a screen
      display showing a highlighted Japanese word and a pop-up menu, including a translation
      of the Japanese word, according to the invention. The following section explains
      the English reference pop-ups associated with each word:<br />(34)  The English
      reference is intended to give the user basic information to help him understand
      a selected word in its context. A majority of the word definitions found in
      the English reference are not the direct translation of the word in that particular
      context. They are mostly generalized definitions of the given word. These pop-up
      fields give the user a quick reference to the word and allow him to continue
      reading or reviewing the text without the need to stop and access a dictionary.
      In applying the invention to other languages, for example Korean or Chinese,
      or to difficult materials, such as highly technical or complex matters, appropriate
      external references should be selected.<br />(35)  In the exemplary embodiment
      of the invention, a priority is placed on making the text readable, rather than
      on creating a detailed grammatical description of it. The English reference
      is not considered a direct translation of the foreign language, but rather is
      preferably a contextual definition based upon the word''s meaning within the
      text.<br />(36)  Definitions<br />(37)  Definitions in dictionaries are written
      for practical use. Accordingly, word and sentence translations are preferably
      written in modern English at a level acceptable to native speakers. The types
      of phrases and words covered by the English reference are preferably of great
      variety. The English translation should therefore be highly readable and useful.<br
      />(38)  Hyper Notes<br />(39)  FIG. 4 is a screen display showing a highlighted
      Japanese word and a pop-up menu, including Japanese language annotations of
      the Japanese word, according to the invention.<br />(40)  Hyper notes are provided
      for a great number of words and phrases included in the system. Most of the
      explanations are grammatical in nature, but others simply explain the passage
      in further depth or rephrase the foreign language word or phrase in simpler
      language. The notes have been written in the foreign language because it is
      believed that this is the best way for students of the language to improve their
      skills. As in the main text, the yomi and meanings of the words are given in
      a pop-up form.<br />(41)  Using the Electronic Viewer Module<br />(42)  The
      electronic viewer module provides the following pull-down menus: File, Edit,
      Words, View.<br />(43)  The File Menu includes: 1. Open (opens up a book for
      reading); 2. Close (closes a book); 3. Personal Dictionary (opens the personal
      dictionary); 4. Import Words (imports a tab delineated file into the personal
      dictionary); 5. Export Words (exports a tab delineated file into the personal
      dictionary); and Quit (quits the applications).<br />(44)  The Edit Menu Includes:
      1. Undo (undoes a previously deleted entry in the personal dictionary fields);
      2. Cut (cuts a highlighted block of text in the personal dictionary fields);
      3. Copy (copies the selected text into the clipboard in either the electronic
      viewer module or the personal dictionary); and 4. Paste (pastes the copied text
      into the target field in the personal dictionary).<br />(45)  The Words Menu
      includes: 1. Find (displays the search dialogue box); 2. Find Next (finds the
      next entry using the previously entered search word); 3. Next (goes to the next
      word in the personal dictionary based on the current sort setting); 4. Prey
      (goes to the previous word in the personal dictionary based on the current sort
      setting); 5. Jump to Text (jumps from the personal dictionary to the source
      of the word in the original text); and 6. Flash Words (displays the words in
      the personal dictionary in slide show fashion).<br />(46)  The View Menu includes:
      1. Browse (sets the program to Browse Mode, indicated by the arrow cursor);
      2. Edit (sets the program to Edit Mode, indicated by the I-beam cursor); 3.
      Show Note Guides (displays the location of the Notes in the text of the viewer);
      4. Show Notes (displays the Notes field in the personal dictionary); 5. Show
      Info (displays the Word Information and sort control button in the personal
      dictionary); and 6. Show Palette (displays the Word Display Palette with the
      electronic viewer module).<br />(47)  After a study session starts, a Table
      of Contents for the selected book appears. By clicking on any item, the user
      is able to go to the desired section of the book. The selected chapter appears
      as a normal text file. The electronic viewer window has a display region with
      a button to display the Table of Contents. The current chapter name of the selected
      book is also displayed in this area. To select a word or phrase in the book,
      the user clicks on a word that is not understood and a pop-up menu immediately
      appears (see FIG. 3). The pop-up information contains the yomi, the English
      reference, and the notes selection. If the pop-up menu does not appear, the
      selected word is not referenced. The yomi also appears in the pop-up menu.<br
      />(48)  To view the English reference information the user selects the English
      Reference from the pop-up menu and the information appears next to the pop-up
      menu.<br />(49)  To see the Note associated with the text, the user selects
      Notes from the pop-up menu and the Note appears in a separate window. If the
      Notes item is gray (for example, as shown in FIG. 3), no Note is available for
      the word. Notes also include a pop-up reference feature. The first word in the
      text with reference information has a black underbar beneath it. This is the
      Word Pointer, which indicates the most recent location for the pop-up menu and
      defaults to the first word. To see where a Note begins and ends, the user selects
      Show Note Guides from the View Menu.<br />(50)  The electronic viewer module
      also provides a Palette. To display the palette, the user selects Show Palette
      from the View Menu. The Word Display Palette displays all the reference information
      for quick viewing. The arrow buttons move the location of the Word Pointer and
      update the reference information. The See Note command displays the Note if
      one exists for the word and is gray if one is not present. The Add to PD command
      automatically copies the word and its associated information to the personal
      dictionary. If a Note is present, it is also copied to the personal dictionary.<br
      />(51)  A limited amount of text can be copied from the book by selecting Edit
      Mode from the View Menu, highlighting the desired text, and selecting Copy from
      the Edit Menu. Words can be searched for in the book by selecting Find from
      the Words Menu.<br />(52)  Using the Personal Dictionary Module<br />(53)  FIG.
      5 is a screen display showing a Japanese word listed in a personal dictionary,
      as well as a personal dictionary control panel, according to the invention.
      The personal dictionary module in the exemplary embodiment of the invention
      is implemented in a relational database that is optimized for managing and studying
      words. Unlike electronic dictionaries where only the word entries of the dictionary
      are searchable, the personal dictionary module allows a user to search on each
      of the eight or more keys associated with a word, as discussed above. To open
      the personal dictionary, the user selects Personal Dictionary from the File
      menu or double clicks on a Personal Dictionary icon.<br />(54)  The words contained
      in the personal dictionary are displayed in large fields with the word on the
      bottom, the yomi above the word, and the English reference on top, as shown
      in FIG. 5. In Browse Mode, clicking on a word alternately hides and shows the
      word. This function is used to enhance review and study of the Main Control
      Buttons.Iadd.. .Iaddend.The Main Control Buttons are located just below the
      Word field. The arrow keys display the next or previous words based on the sort
      key indicated by the Sort Button in the bottom left corner. The Show Notes button
      displays the Note information about the Word. This button toggles to Hide Notes
      when the field is displayed and Show Notes when hidden. Additional notes and
      annotations can be entered directly. The Quick Search button displays the word
      in a pop-window for quick search of a single character. After the pop-up is
      displayed, the user can click on the desired character to search. The Flash
      Words button displays the words in the personal dictionary in slide show fashion.
      Sort order or random order are selectable: sort order uses the current sort
      order.<br />(55)  The Find button displays the search dialogue window. Words
      are searchable by the following keys: Word, Yomi, English Reference, Category,
      Source, Priority, or Date. The personal dictionary supports logical &quot;AND&quot;
      searching for each of the above keys. The following features are supported:
      1. Jump to Text--this button jumps control and display from the personal dictionary
      to the source of the word in the original text; 2. Show Info--this button displays
      the Word Information Buttons, as well as the Date Indicator; this button toggles
      to Hide Info when displayed, and Show Info when hidden; and 3. Word Information--this
      button appears on the bottom of the screen and has the following functions:  a.
      Current Sort--sets the sort order for the Dictionary to either Category, Source,
      Priority, or Date; b. Category--provides for a set of predefined Categories
      for words as well as the ability to add new Categories; c. Source--indicates
      the source of the Word: user entered words are indicated by the user name or
      if not available, by the default User; d. Priority--allows the user to assign
      a priority to a word from 1 to 5; and e. Date Display--the date is displayed
      in the bottom right hand corner; the date is automatically updated each time
      the word is displayed. Searching<br />(56)  Both the electronic viewer module
      and the personal dictionary module provide search features accessible via the
      Word Menu. After selecting Find from the menu, the search dialogue appears.<br
      />(57)  The electronic viewer module includes a simple search feature that allows
      the user to search for a string of text anywhere in the book. The user enters
      the desired text and clicks Find to execute the Search. Find Next searches for
      the next occurrence of the word in the text.<br />(58)  In the personal dictionary,
      a slightly more complex search feature is provided. The search dialogue allows
      the user to enter multiple search terms. For example, a user can search for
      a certain term in the `Economics` category or the user can look for a Kanji
      that has a certain reading. More search terms result in increased search time.
      The search term for Word, Yomi, Reference, Note, and Source are indexed based
      on the first seven characters contained in the field. Characters appearing after
      the seventh character in any of these fields are not found with the `Starts
      With` selection. Selecting `Contains` searches the entire text in the field.<br
      />(59)  To search, the user enters the desired word or character and then selects
      `Starts With` or `Contains` from the menu. A `Starts With` search is the fastest.
      The `Category` search terms are based on the category list. The integers 1 to
      5 can be entered for `Priority.` Date searching can be performed as `is`, `is
      before`, or `is after.` After entering the desired search information, the user
      clicks `Find` to execute the Search. Find Next searches for the next occurrence
      in the personal dictionary.<br />(60)  Importing/Exporting Word Lists<br />(61)  Text
      files can be read into the personal dictionary to make data exchange with other
      programs and colleagues feasible. The following format should be followed to
      allow accurate importing. One may use a spreadsheet program to build the word
      table and export the information as a tab delimited file. If a word processor
      is used, the user must add an extra tab for blank fields and follow the format
      listed below. In the exemplary embodiment of the invention, Export and Import
      uses the following format:<br />(62)   TABLE-US-00001 Word\t[TAB]; Pronunciation\t[TAB];
      Meaning\t[TAB]; Notes\t[TAB]; Category\t[TAB]; Source\t[TAB]; Priority\t[TAB];
      and Date\t[Hard Return].<br />(63)  Setting up the Word field as column A in
      a spreadsheet and then exporting as a text file results in this format. If a
      word processor is used, one should also save as a text file. One should not
      include any hard returns (user entered returns) within the string of text for
      the given word. If given the option, the user should elect to have soft returns
      (automatically entered returns) deleted. To import, the user selects Import
      Words from the File Menu, and then chooses the file for import. To export, the
      user selects Export Words from the File Menu, and then enters a name for the
      given file.<br />(64)  Although the invention is described herein with reference
      to the preferred embodiment, one skilled in the art will readily appreciate
      that other applications may be substituted for those set forth herein without
      departing from the spirit and scope of the present invention. For example, the
      invention may be used to index images such that elements of the image are linked
      to an external reference. Thus, an illustration of the human body may include
      descriptive external resources for each of the body''s internal organs, and
      would thereby aid in the study of anatomy. Likewise, a video or other moving
      picture display, for example animated displays, could be indexed such that the
      picture could be stopped and various elements within a frame of the picture
      could be examined through links to external references. The invention allows
      such application because it does not embed information within the source material
      as is the case with prior art hyperlink technology. Rather, the invention creates
      a physical counterpart to the image in which a selected image position defines
      an offset that locates a desired external reference. Accordingly, the invention
      should only be limited by the claims included below.","claimsHtml":".[.1. A
      system for linking source material to reference material for display comprising:
      a source material image including a plurality of discrete pieces having links
      to external reference materials comprising any of textual, audio, video, and
      picture information, said source material image stored in an electronic database;
      means for determining an address on said electronic database for the beginning
      position of said source material image; means for cutting said source material
      image into said discrete pieces; means for determining an address on said electronic
      database for a start point and an end point of said discrete pieces of said
      image based upon said beginning position of said source material image; means
      for recording said start and said end point addresses in a look-up table; means
      for selecting a discrete portion of said source material image; means for determining
      the address on said electronic database of said selected discrete portion; means
      for converting said address of said selected discrete portion to an offset value
      from said beginning position address of said source material image; means for
      comparing said offset value with said recorded start and end point addresses
      of said discrete pieces in said look-up table; means for selecting an external
      reference that corresponds to said look-up table start and end point addresses;
      and means for reproducing said external reference..].<br /> .[.2. The system
      of claim 1, further comprising: a linking engine for linking said source material
      to said reference information on any of a word-by-word and phrase-by-phrase
      basis..].<br /> .[.3. The system of claim 2, said linking engine further comprising:
      word cut means for dividing said source material into discrete pieces; linking
      means for establishing at least one link between each of said discrete pieces
      and said reference information; compiler means for assembling an integrated
      source image from said discrete pieces; indexing means for linking said assembled
      discrete pieces to said reference information..].<br /> .[.4. The system of
      claim 3, said linking engine further comprising: means for building an index
      to link each of said source material pieces to said reference information..].<br
      /> .[.5. The system of claim 4, wherein said index links said source material
      pieces to said reference information based upon the value of the offset of the
      starting and ending position addresses of said source material pieces from the
      beginning position address of said integrated source image..].<br /> .[.6. The
      system of claim 5, wherein said offset locates said reference information to
      a corresponding source material piece based upon offset occurrence within a
      range defined by the value of the offsets of the starting and ending point addresses
      of said source material pieces from said beginning position address of said
      integrated source image..].<br /> .[.7. The system of claim 1, further comprising:
      means for manipulating said stored source material and reference information
      with at least two user keys..].<br /> .[.8. A method for linking source material
      to reference material for display, comprising: determining the beginning position
      address of a source material image stored in an electronic database, said source
      material image including a plurality of discrete pieces having links to external
      reference materials comprising any of textual, audio, video, and picture information;
      cutting said source material image into said discrete pieces; determining a
      starting point address and an ending point address of said discrete pieces of
      said image based upon said beginning position address of said source material
      image; recording said starting and said ending addresses in a look-up table;
      selecting a discrete portion of said source material image; determining the
      address of said selected discrete portion; converting said address of said selected
      discrete portion to an offset value from said beginning position address of
      said source material image; comparing said offset value with said recorded start
      and end point addresses of said discrete pieces in said look-up table; selecting
      an external reference that corresponds to said look-up table start and end point
      addresses; and reproducing said external reference..].<br /> .[.9. In a language
      learning method, a method for linking source material to reference material
      for display, comprising the steps of: reading a foreign language source material
      image including a plurality of discrete pieces having links to external reference
      materials comprising any of textual, audio, video, and picture information with
      an electronic viewer; accessing reference materials on selected portions of
      said source material image; determining the beginning position address of said
      source material image; cutting said source material image into said discrete
      pieces; determining a start point address and an end point address of said discrete
      pieces of said image based upon said beginning position address of said source
      material image; recording said start and said end point addresses in a look-up
      table; selecting a discrete portion of said source material image; determining
      the address of said selected discrete portion; converting said address of said
      selected discrete portion to an offset value from said beginning position address
      of said source material image; comparing said offset value with said recorded
      start and end point addresses of said discrete pieces in said look-up table;
      selecting an external reference that corresponds to said look-up table start
      and end point addresses; and reproducing said external reference..].<br /> .[.10.
      The method of claim 9, further comprising the step of: linking said source material
      to said reference information with a linking engine on any of a word-by-word
      and phrase-by-phrase basis..].<br /> .[.11. The method of claim 10, said linking
      step further comprising the steps of: dividing said source material into discrete
      pieces; establishing at least one link between each of said discrete pieces
      and said reference information; assembling an integrated source image from said
      discrete pieces; and linking said assembled discrete pieces to said reference
      information..].<br /> .[.12. The method of claim 11, said linking step further
      comprising the step of: building an index to link each of said source material
      pieces to said reference information..].<br /> .[.13. The method of claim 12,
      wherein said index links said source material pieces to said reference information
      based upon the offset between the starting position address for said source
      material pieces and the beginning position address of said integrated source
      image..].<br /> .[.14. The method of claim 13, wherein said offset locates said
      reference information to a corresponding source material piece based upon offset
      occurrence within a range defined by the value of the offsets of the starting
      and ending position addresses of said source material pieces from said beginning
      position address of said integrated source image..].<br /> .[.15. In a language
      learning system, a system for linking source material to reference material
      for display, comprising: a text image including a plurality of discrete pieces
      having links to external reference materials comprising any of textual, audio,
      video, and picture information; means for determining the beginning position
      address of said text image; means for cutting said text image into said discrete
      pieces; means for determining a starting point address and an ending point address
      of said discrete pieces of said image based upon said beginning position address
      of said source material image; means for recording said starting and said ending
      point addresses in a look-up table; means for selecting a discrete portion of
      said text image; means for determining the address of said selected discrete
      portion; means for converting said address of said selected discrete portion
      to an offset value from said beginning position address of said source material
      image; means for comparing said offset value with said recorded start and end
      point addresses of said discrete pieces in said look-up table; means for selecting
      an external reference that corresponds to said look-up table start and end point
      addresses; and means for displaying said external reference..].<br /> .[.16.
      In a language learning method, a method for linking source material to reference
      material for display, comprising the steps of: determining the beginning position
      address of a text image, said text image including a plurality of discrete pieces
      having links to external reference materials comprising any of textual, audio,
      video, and picture information; cutting said source material image into said
      discrete pieces; determining a starting point address and an ending point address
      of said discrete pieces of said image based upon said beginning position address
      of said text image; recording said starting and said ending point addresses
      in a look-up table; selecting a discrete portion of said text image; determining
      the address of said selected discrete portion; converting said address of said
      selected discrete portion to an offset value from said beginning position of
      said text image; comparing said offset value with said recorded start and end
      point addresses of said discrete pieces in said look-up table; selecting an
      external reference that corresponds to said look-up table start and end point
      address; and displaying said external reference..].<br /> .Iadd.17. A system
      for linking textual source material to external reference materials for display,
      the system comprising: means for determining a beginning position address of
      a textual source material stored in an electronic database; means for cutting
      the textual source material into a plurality of discrete pieces; means for determining
      starting point addresses and ending point addresses of the plurality of discrete
      pieces based upon the beginning position address; means for recording in a look-up
      table the starting and ending point addresses; means for linking the plurality
      of discrete pieces to external reference materials by recording in the look-up
      table, along with the starting and ending point addresses of the plurality of
      discrete pieces, links to the external reference materials, the external reference
      materials comprising any of textual, audio, video, and picture information;
      means for selecting a discrete portion of an image of the source material; means
      for determining a display address of the selected discrete portion; means for
      converting the display address of the selected discrete portion to an offset
      value from the beginning position address; means for comparing the offset value
      with the starting and ending point addresses recorded in the look-up table to
      identify one of the plurality of discrete pieces; means for selecting one of
      the external reference materials corresponding to the identified one of the
      plurality of discrete pieces; and means for displaying on a computer the selected
      one of the external reference materials..Iaddend.<br /> .Iadd.18. The system
      of claim 17, wherein the means for linking links the plurality of discrete pieces
      to external reference materials on a word-by-word or phrase-by-phrase basis..Iaddend.<br
      /> .Iadd.19. The system of claim 18, further comprising: means for compiling
      the source material image from at least the plurality of discrete pieces; and
      means for indexing the plurality of discrete pieces and corresponding links
      to the external reference materials..Iaddend.<br /> .Iadd.20. The system of
      claim 19, further comprising: means for building an index for each of the linked
      external reference materials..Iaddend.<br /> .Iadd.21. The system of claim 20,
      wherein the look-up table links the identified one of the plurality of discrete
      pieces to at least a corresponding one of the external reference materials based
      upon the offset value..Iaddend.<br /> .Iadd.22. The system of claim 21, wherein
      the identified one of the plurality of discrete pieces is identified based upon
      the offset value being within a range defined by the starting and ending point
      addresses of the identified one of the plurality of discrete pieces..Iaddend.<br
      /> .Iadd.23. The system of claim 17, further comprising: means for manipulating
      the source material image and the external reference materials with at least
      two user keys..Iaddend.<br /> .Iadd.24. The system of claim 17, wherein cutting
      the textual source material into a plurality of discrete pieces is done manually..Iaddend.<br
      /> .Iadd.25. The system of claim 17, wherein cutting the textual source material
      into a plurality of discrete pieces is done automatically..Iaddend.<br /> .Iadd.26.
      The system of claim 25, wherein automatically cutting the textual source material
      into a plurality of discrete pieces is done using a grammar parser..Iaddend.<br
      /> .Iadd.27. The system of claim 25, wherein automatically cutting the textual
      source material into a plurality of discrete pieces is done without using tags..Iaddend.<br
      /> .Iadd.28. The system of claim 25, wherein automatically cutting the textual
      source material into a plurality of discrete pieces is done without reference
      to any tags which may be located in the textual source material..Iaddend.<br
      /> .Iadd.29. The system of claim 17, wherein the link is a hyperlink..Iaddend.<br
      /> .Iadd.30. The system of claim 17, wherein the link is an address of the selected
      one of the external reference materials..Iaddend.<br /> .Iadd.31. The system
      of claim 17, wherein the link is reference information for retrieving the selected
      one of the external reference materials..Iaddend.<br /> .Iadd.32. The system
      of claim 17, wherein determining a display address of the selected discrete
      portion is done without using tags..Iaddend.<br /> .Iadd.33. The system of claim
      17, wherein determining a display address of the selected discrete portion is
      done without reference to any tags which may be located in the textual source
      material..Iaddend.<br /> .Iadd.34. The system of claim 17, wherein determining
      a display address of the selected discrete portion is done without reference
      to any hierarchical information which may be located in the textual source material..Iaddend.<br
      /> .Iadd.35. The system of claim 17, wherein converting the display address
      of the selected discrete portion to an offset value from the beginning position
      address is done without using tags..Iaddend.<br /> .Iadd.36. The system of claim
      17, wherein converting the display address of the selected discrete portion
      to an offset value from the beginning position address is done without reference
      to any tags which may be located in the textual source material..Iaddend.<br
      /> .Iadd.37. The system of claim 17, wherein converting the display address
      of the selected discrete portion to an offset value from the beginning position
      address is done without reference to any hierarchical information which may
      be located in the textual source material..Iaddend.<br /> .Iadd.38. The system
      of claim 17, wherein comparing the offset value with the starting and ending
      point addresses recorded in the look-up table to identify one of the plurality
      of discrete pieces is done without using tags..Iaddend.<br /> .Iadd.39. The
      system of claim 17, wherein comparing the offset value with the starting and
      ending point addresses recorded in the look-up table to identify one of the
      plurality of discrete pieces is done without reference to any tags which may
      be located in the textual source material..Iaddend.<br /> .Iadd.40. The system
      of claim 17, wherein comparing the offset value with the starting and ending
      point addresses recorded in the look-up table to identify one of the plurality
      of discrete pieces is done without reference to any hierarchical information
      which may be located in the textual source material..Iaddend.<br /> .Iadd.41.
      The system of claim 17, wherein the external reference materials comprise a
      plurality of text based external reference materials..Iaddend.<br /> .Iadd.42.
      The system of claim 17, wherein the external reference materials comprise a
      plurality of image based external reference materials..Iaddend.<br /> .Iadd.43.
      The system of claim 17, wherein the external reference materials comprise a
      plurality of graphic based external reference materials..Iaddend.<br /> .Iadd.44.
      The system of claim 17, wherein the external reference materials comprise a
      plurality of audio based external reference materials..Iaddend.<br /> .Iadd.45.
      The system of claim 17, wherein the external reference materials comprise a
      plurality of video based external reference materials..Iaddend.<br /> .Iadd.46.
      The system of claim 17, wherein at least one of the external reference materials
      is a combination of two or more of text based external reference material, image
      based external reference material, graphic based external reference material,
      audio based external reference material, and video based external reference
      material..Iaddend.<br /> .Iadd.47. The system of claim 17, wherein linking the
      plurality of discrete pieces is done manually..Iaddend.<br /> .Iadd.48. The
      system of claim 17, wherein linking the plurality of discrete pieces is done
      automatically..Iaddend.<br /> .Iadd.49. The system of claim 17, wherein the
      electronic database is an electronic relational database..Iaddend.<br /> .Iadd.50.
      The system of claim 17, wherein the electronic database is an electronic file..Iaddend.<br
      /> .Iadd.51. The system of claim 17, wherein the electronic database is electronic
      text..Iaddend.<br /> .Iadd.52. The system of claim 17, wherein the beginning
      position address is a beginning location of the textual source material in the
      electronic database..Iaddend.<br /> .Iadd.53. The system of claim 52, wherein
      each starting point address is a starting location of at least one of the plurality
      of discrete pieces based upon the beginning location of the textual source material..Iaddend.<br
      /> .Iadd.54. The system of claim 52, wherein each ending point address is an
      ending location of at least one of the plurality of discrete pieces based upon
      the beginning location of the textual source material..Iaddend.<br /> .Iadd.55.
      The system of claim 17, further comprising: means for displaying the external
      reference materials corresponding to the identified one of the plurality of
      discrete pieces in a pop-up menu, prior to selecting one of the external reference
      materials corresponding to the identified one of the plurality of discrete pieces..Iaddend.<br
      /> .Iadd.56. The system of claim 55, wherein the pop-up menu is displayed in
      the textual source material image next to the selected discrete portion..Iaddend.<br
      /> .Iadd.57. The system of claim 55, wherein the selected one of the external
      reference materials is selected using the pop-up menu..Iaddend.<br /> .Iadd.58.
      The system of claim 55, wherein the pop-up menu displays labels for the external
      reference materials corresponding to the identified one of the plurality of
      discrete pieces..Iaddend.<br /> .Iadd.59. The system of claim 55, wherein the
      labels can each be selected in the pop-up menu to display the external reference
      materials corresponding to the identified one of the plurality of discrete pieces..Iaddend.<br
      /> .Iadd.60. The system of claim 17, wherein the selected one of the external
      reference materials is a single word..Iaddend.<br /> .Iadd.61. The system of
      claim 17, wherein each of the external reference materials is a single word..Iaddend.<br
      /> .Iadd.62. A computer-implemented method for linking textual source material
      to external reference materials for display, the method comprising the steps
      of: determining a beginning position address of textual source material stored
      in an electronic database; cutting the textual source material into a plurality
      of discrete pieces; determining starting point addresses and ending point addresses
      of the plurality of discrete pieces based upon the beginning position address;
      recording in a look up table the starting and ending point addresses; linking
      the plurality of discrete pieces to external reference materials by recording
      in the look-up table, along with the starting and ending point addresses of
      the plurality of discrete pieces, links to the external reference materials,
      the external reference materials comprising any of textual, audio, video, and
      picture information; selecting a discrete portion of an image of the textual
      source material; determining a display address of the selected discrete portion;
      converting the display address of the selected discrete portion to an offset
      value from the beginning position address; comparing the offset value with the
      starting and ending point addresses recorded in the look-up table to identify
      one of the plurality of discrete pieces; selecting one of the external reference
      materials corresponding to the identified one of the plurality of discrete pieces;
      and displaying on a computer the selected one of the external reference materials..Iaddend.<br
      /> .Iadd.63. The method of claim 62, wherein cutting the textual source material
      into a plurality of discrete pieces is done manually..Iaddend.<br /> .Iadd.64.
      The method of claim 62, wherein cutting the textual source material into a plurality
      of discrete pieces is done automatically..Iaddend.<br /> .Iadd.65. The method
      of claim 64, wherein automatically cutting the textual source material into
      a plurality of discrete pieces is done using a grammar parser..Iaddend.<br />
      .Iadd.66. The method of claim 64, wherein automatically cutting the textual
      source material into a plurality of discrete pieces is done without using tags..Iaddend.<br
      /> .Iadd.67. The method of claim 64, wherein automatically cutting the textual
      source material into a plurality of discrete pieces is done without reference
      to any tags which may be located in the textual source material..Iaddend.<br
      /> .Iadd.68. The method of claim 62, wherein the link is a hyperlink..Iaddend.<br
      /> .Iadd.69. The method of claim 62, wherein the link is an address of the selected
      one of the external reference materials..Iaddend.<br /> .Iadd.70. The method
      of claim 62, wherein the link is reference information for retrieving the selected
      one of the external reference materials..Iaddend.<br /> .Iadd.71. The method
      of claim 62, wherein determining a display address of the selected discrete
      portion is done without using tags..Iaddend.<br /> .Iadd.72. The method of claim
      62, wherein determining a display address of the selected discrete portion is
      done without reference to any tags which may be located in the textual source
      material..Iaddend.<br /> .Iadd.73. The method of claim 62, wherein determining
      a display address of the selected discrete portion is done without reference
      to any hierarchical information which may be located in the textual source material..Iaddend.<br
      /> .Iadd.74. The method of claim 62, wherein converting the display address
      of the selected discrete portion to an offset value from the beginning position
      address is done without using tags..Iaddend.<br /> .Iadd.75. The method of claim
      62, wherein converting the display address of the selected discrete portion
      to an offset value from the beginning position address is done without reference
      to any tags which may be located in the textual source material..Iaddend.<br
      /> .Iadd.76. The method of claim 62, wherein converting the display address
      of the selected discrete portion to an offset value from the beginning position
      address is done without reference to any hierarchical information which may
      be located in the textual source material..Iaddend.<br /> .Iadd.77. The method
      of claim 62, wherein comparing the offset value with the starting and ending
      point addresses recorded in the look-up table to identify one of the plurality
      of discrete pieces is done without using tags..Iaddend.<br /> .Iadd.78. The
      method of claim 62, wherein comparing the offset value with the starting and
      ending point addresses recorded in the look-up table to identify one of the
      plurality of discrete pieces is done without reference to any tags which may
      be located in the textual source material..Iaddend.<br /> .Iadd.79. The method
      of claim 62, wherein comparing the offset value with the starting and ending
      point addresses recorded in the look-up table to identify one of the plurality
      of discrete pieces is done without reference to any hierarchical information
      which may be located in the textual source material..Iaddend.<br /> .Iadd.80.
      The method of claim 62, wherein the external reference materials comprise a
      plurality of text based external reference materials..Iaddend.<br /> .Iadd.81.
      The method of claim 62, wherein the external reference materials comprise a
      plurality of image based external reference materials..Iaddend.<br /> .Iadd.82.
      The method of claim 62, wherein the external reference materials comprise a
      plurality of graphic based external reference materials..Iaddend.<br /> .Iadd.83.
      The method of claim 62, wherein the external reference materials comprise a
      plurality of audio based external reference materials..Iaddend.<br /> .Iadd.84.
      The method of claim 62, wherein the external reference materials comprise a
      plurality of video based external reference materials..Iaddend.<br /> .Iadd.85.
      The method of claim 62, wherein at least one of the external reference materials
      is a combination of two or more of text based external reference material, image
      based external reference material, graphic based external reference material,
      audio based external reference material, and video based external reference
      material..Iaddend.<br /> .Iadd.86. The method of claim 62, wherein linking the
      plurality of discrete pieces is done manually..Iaddend.<br /> .Iadd.87. The
      method of claim 62, wherein linking the plurality of discrete pieces is done
      automatically..Iaddend.<br /> .Iadd.88. The method of claim 62, wherein the
      electronic database is an electronic relational database..Iaddend.<br /> .Iadd.89.
      The method of claim 62, wherein the electronic database is an electronic file..Iaddend.<br
      /> .Iadd.90. The method of claim 62, wherein the electronic database is electronic
      text..Iaddend.<br /> .Iadd.91. The method of claim 62, wherein the beginning
      position address is a beginning location of the textual source material in the
      electronic database..Iaddend.<br /> .Iadd.92. The method of claim 91, wherein
      each starting point address is a starting location of at least one of the plurality
      of discrete pieces based upon the beginning location of the textual source material..Iaddend.<br
      /> .Iadd.93. The method of claim 91, wherein each ending point address is an
      ending location of at least one of the plurality of discrete pieces based upon
      the beginning location of the textual source material..Iaddend.<br /> .Iadd.94.
      The method of claim 62, further comprising: displaying the external reference
      materials corresponding to the identified one of the plurality of discrete pieces
      in a pop-up menu, prior to selecting one of the external reference materials
      corresponding to the identified one of the plurality of discrete pieces..Iaddend.<br
      /> .Iadd.95. The method of claim 94, wherein the pop-up menu is displayed in
      the textual source material image next to the selected discrete portion..Iaddend.<br
      /> .Iadd.96. The method of claim 94, wherein the selected one of the external
      reference materials is selected using the pop-up menu..Iaddend.<br /> .Iadd.97.
      The method of claim 94, wherein the pop-up menu displays labels for the external
      reference materials corresponding to the identified one of the plurality of
      discrete pieces..Iaddend.<br /> .Iadd.98. The method of claim 94, wherein the
      labels can each be selected in the pop-up menu to display the external reference
      materials corresponding to the identified one of the plurality of discrete pieces..Iaddend.<br
      /> .Iadd.99. The method of claim 62, wherein the selected one of the external
      reference materials is a single word..Iaddend.<br /> .Iadd.100. The method of
      claim 62, wherein each of the external reference materials is a single word..Iaddend.<br
      /> .Iadd.101. A system for linking textual source material to external reference
      materials for display, the system comprising: means for determining a beginning
      position address of a textual source material stored in an electronic database;
      means for cutting the textual source material into a plurality of discrete pieces;
      means for determining a starting point address and an ending point address of
      at least one of the plurality of discrete pieces based upon the beginning position
      address; means for recording in a look-up table the starting and ending point
      addresses; means for linking at least one of the plurality of discrete pieces
      to at least one of a plurality of external reference materials by recording
      in the look-up table, along with the starting and ending point addresses of
      the at least one of the plurality of discrete pieces, a link to the at least
      one of the plurality of external reference materials, the plurality of external
      reference materials comprising any of textual, audio, video, and picture information;
      means for selecting a discrete portion of an image of the source material; means
      for determining a display address of the selected discrete portion; means for
      converting the display address of the selected discrete portion to an offset
      value from the beginning position address; means for comparing the offset value
      with the starting and ending point addresses recorded in the look-up table to
      identify one of the plurality of discrete pieces; means for selecting one of
      the at least one of the plurality of external reference materials corresponding
      to the identified one of the plurality of discrete pieces; and means for displaying
      on a computer the selected one of the plurality of external reference materials..Iaddend.<br
      /> .Iadd.102. The system of claim 101, wherein the means for linking links at
      least one of the plurality of discrete pieces to at least one of a plurality
      of external reference materials on a word-by-word or phrase-by-phrase basis..Iaddend.<br
      /> .Iadd.103. The system of claim 102, further comprising: means for compiling
      the source material image from at least the plurality of discrete pieces; and
      means for indexing at least one of the plurality of discrete pieces and corresponding
      links to the plurality of external reference materials..Iaddend.<br /> .Iadd.104.
      The system of claim 103, further comprising: means for building an index for
      each of the linked plurality of external reference materials..Iaddend.<br />
      .Iadd.105. The system of claim 104, wherein the look-up table links the identified
      one of the plurality of discrete pieces to at least a corresponding one of a
      plurality of external reference materials based upon the offset value..Iaddend.<br
      /> .Iadd.106. The system of claim 105, wherein the identified one of the plurality
      of discrete pieces is identified based upon the offset value being within a
      range defined by the starting and ending point addresses of the identified one
      of the plurality of discrete pieces..Iaddend.<br /> .Iadd.107. The system of
      claim 101, further comprising: means for manipulating the source material image
      and the plurality of external reference materials with at least two user keys..Iaddend.<br
      /> .Iadd.108. The system of claim 101, wherein cutting the textual source material
      into a plurality of discrete pieces is done manually..Iaddend.<br /> .Iadd.109.
      The system of claim 101, wherein cutting the textual source material into a
      plurality of discrete pieces is done automatically..Iaddend.<br /> .Iadd.110.
      The system of claim 109, wherein automatically cutting the textual source material
      into a plurality of discrete pieces is done using a grammar parser..Iaddend.<br
      /> .Iadd.111. The system of claim 109, wherein automatically cutting the textual
      source material into a plurality of discrete pieces is done without using tags..Iaddend.<br
      /> .Iadd.112. The system of claim 109, wherein automatically cutting the textual
      source material into a plurality of discrete pieces is done without reference
      to any tags which may be located in the textual source material..Iaddend.<br
      /> .Iadd.113. The system of claim 101, wherein the link is a hyperlink..Iaddend.<br
      /> .Iadd.114. The system of claim 101, wherein the link is an address of the
      selected one of the plurality of external reference materials..Iaddend.<br />
      .Iadd.115. The system of claim 101, wherein the link is reference information
      for retrieving the selected one of the plurality of external reference materials..Iaddend.<br
      /> .Iadd.116. The system of claim 101, wherein determining a display address
      of the selected discrete portion is done without using tags..Iaddend.<br />
      .Iadd.117. The system of claim 101, wherein determining a display address of
      the selected discrete portion is done without reference to any tags which may
      be located in the textual source material..Iaddend.<br /> .Iadd.118. The system
      of claim 101, wherein determining a display address of the selected discrete
      portion is done without reference to any hierarchical information which may
      be located in the textual source material..Iaddend.<br /> .Iadd.119. The system
      of claim 101, wherein converting the display address of the selected discrete
      portion to an offset value from the beginning position address is done without
      using tags..Iaddend.<br /> .Iadd.120. The system of claim 101, wherein converting
      the display address of the selected discrete portion to an offset value from
      the beginning position address is done without reference to any tags which may
      be located in the textual source material..Iaddend.<br /> .Iadd.121. The system
      of claim 101, wherein converting the display address of the selected discrete
      portion to an offset value from the beginning position address is done without
      reference to any hierarchical information which may be located in the textual
      source material..Iaddend.<br /> .Iadd.122. The system of claim 101, wherein
      comparing the offset value with the starting and ending point addresses recorded
      in the look-up table to identify one of the plurality of discrete pieces is
      done without using tags..Iaddend.<br /> .Iadd.123. The system of claim 101,
      wherein comparing the offset value with the starting and ending point addresses
      recorded in the look-up table to identify one of the plurality of discrete pieces
      is done without reference to any tags which may be located in the textual source
      material..Iaddend.<br /> .Iadd.124. The system of claim 101, wherein comparing
      the offset value with the starting and ending point addresses recorded in the
      look-up table to identify one of the plurality of discrete pieces is done without
      reference to any hierarchical information which may be located in the textual
      source material..Iaddend.<br /> .Iadd.125. The system of claim 101, wherein
      the plurality of external reference materials comprises a plurality of text
      based external reference materials..Iaddend.<br /> .Iadd.126. The system of
      claim 101, wherein the plurality of external reference materials comprises a
      plurality of image based external reference materials..Iaddend.<br /> .Iadd.127.
      The system of claim 101, wherein the plurality of external reference materials
      comprises a plurality of graphic based external reference materials..Iaddend.<br
      /> .Iadd.128. The system of claim 101, wherein the plurality of external reference
      materials comprises a plurality of audio based external reference materials..Iaddend.<br
      /> .Iadd.129. The system of claim 101, wherein the plurality of external reference
      materials comprises a plurality of video based external reference materials..Iaddend.<br
      /> .Iadd.130. The system of claim 101, wherein at least one of the plurality
      of external reference materials is a combination of two or more of text based
      external reference material, image based external reference material, graphic
      based external reference material, audio based external reference material,
      and video based external reference material..Iaddend.<br /> .Iadd.131. The system
      of claim 101, wherein linking at least one of the plurality of discrete pieces
      is done manually..Iaddend.<br /> .Iadd.132. The system of claim 101, wherein
      linking at least one of the plurality of discrete pieces is done automatically..Iaddend.<br
      /> .Iadd.133. The system of claim 101, wherein the electronic database is an
      electronic relational database..Iaddend.<br /> .Iadd.134. The system of claim
      101, wherein the electronic database is an electronic file..Iaddend.<br /> .Iadd.135.
      The system of claim 101, wherein the electronic database is electronic text..Iaddend.<br
      /> .Iadd.136. The system of claim 101, wherein the beginning position address
      is a beginning location of the textual source material in the electronic database..Iaddend.<br
      /> .Iadd.137. The system of claim 136, wherein each starting point address is
      a starting location of at least one of the plurality of discrete pieces based
      upon the beginning location of the textual source material..Iaddend.<br /> .Iadd.138.
      The system of claim 136, wherein each ending point address is an ending location
      of at least one of the plurality of discrete pieces based upon the beginning
      location of the textual source material..Iaddend.<br /> .Iadd.139. The system
      of claim 101, further comprising: means for displaying the plurality of external
      reference materials corresponding to the identified one of the plurality of
      discrete pieces in a pop-up menu, prior to selecting one of the at least one
      of the plurality of external reference materials corresponding to the identified
      one of the plurality of discrete pieces..Iaddend.<br /> .Iadd.140. The system
      of claim 139, wherein the pop-up menu is displayed in the textual source material
      image next to the selected discrete portion..Iaddend.<br /> .Iadd.141. The system
      of claim 139, wherein the selected one of the plurality of external reference
      materials is selected using the pop-up menu..Iaddend.<br /> .Iadd.142. The system
      of claim 139, wherein the pop-up menu displays labels for the plurality of external
      reference materials corresponding to the identified one of the plurality of
      discrete pieces..Iaddend.<br /> .Iadd.143. The system of claim 139, wherein
      the labels can each be selected in the pop-up menu to display the at least one
      of the plurality of external reference materials corresponding to the identified
      one of the plurality of discrete pieces..Iaddend.<br /> .Iadd.144. The system
      of claim 101, wherein the at least one of the plurality of external reference
      materials is a single word..Iaddend.<br /> .Iadd.145. The system of claim 101,
      wherein each of the plurality of external reference materials is a single word..Iaddend.<br
      /> .Iadd.146. A computer-implemented method for linking textual source material
      to external reference materials for display, the method comprising the steps
      of: determining a beginning position address of textual source material stored
      in an electronic database; cutting the textual source material into a plurality
      of discrete pieces; determining a starting point address and an ending point
      address of at least one of the plurality of discrete pieces based upon the beginning
      position address; recording in a look up table the starting and ending point
      addresses; linking at least one of the plurality of discrete pieces to at least
      one of a plurality of external reference materials by recording in the look-up
      table, along with the starting and ending point addresses of the at least one
      of the plurality of discrete pieces, a link to the at least one of the plurality
      of external reference materials, the plurality of external reference materials
      comprising any of textual, audio, video, and picture information; selecting
      a discrete portion of an image of the textual source material; determining a
      display address of the selected discrete portion; converting the display address
      of the selected discrete portion to an offset value from the beginning position
      address; comparing the offset value with the starting and ending point addresses
      recorded in the look-up table to identify one of the plurality of discrete pieces;
      selecting one of the at least one of the plurality of external reference materials
      corresponding to the identified one of the plurality of discrete pieces; and
      displaying on a computer the selected one of the plurality of external reference
      materials..Iaddend.<br /> .Iadd.147. The method of claim 146, wherein cutting
      the textual source material into a plurality of discrete pieces is done manually..Iaddend.<br
      /> .Iadd.148. The method of claim 146, wherein cutting the textual source material
      into a plurality of discrete pieces is done automatically..Iaddend.<br /> .Iadd.149.
      The method of claim 148, wherein automatically cutting the textual source material
      into a plurality of discrete pieces is done using a grammar parser..Iaddend.<br
      /> .Iadd.150. The method of claim 148, wherein automatically cutting the textual
      source material into a plurality of discrete pieces is done without using tags..Iaddend.<br
      /> .Iadd.151. The method of claim 148, wherein automatically cutting the textual
      source material into a plurality of discrete pieces is done without reference
      to any tags which may be located in the textual source material..Iaddend.<br
      /> .Iadd.152. The method of claim 146, wherein the link is a hyperlink..Iaddend.<br
      /> .Iadd.153. The method of claim 146, wherein the link is an address of the
      selected one of the plurality of external reference materials..Iaddend.<br />
      .Iadd.154. The method of claim 146, wherein the link is reference information
      for retrieving the selected one of the plurality of external reference materials..Iaddend.<br
      /> .Iadd.155. The method of claim 146, wherein determining a display address
      of the selected discrete portion is done without using tags..Iaddend.<br />
      .Iadd.156. The method of claim 146, wherein determining a display address of
      the selected discrete portion is done without reference to any tags which may
      be located in the textual source material..Iaddend.<br /> .Iadd.157. The method
      of claim 146, wherein determining a display address of the selected discrete
      portion is done without reference to any hierarchical information which may
      be located in the textual source material..Iaddend.<br /> .Iadd.158. The method
      of claim 146, wherein converting the display address of the selected discrete
      portion to an offset value from the beginning position address is done without
      using tags..Iaddend.<br /> .Iadd.159. The method of claim 146, wherein converting
      the display address of the selected discrete portion to an offset value from
      the beginning position address is done without reference to any tags which may
      be located in the textual source material..Iaddend.<br /> .Iadd.160. The method
      of claim 146, wherein converting the display address of the selected discrete
      portion to an offset value from the beginning position address is done without
      reference to any hierarchical information which may be located in the textual
      source material..Iaddend.<br /> .Iadd.161. The method of claim 146, wherein
      comparing the offset value with the starting and ending point addresses recorded
      in the look-up table to identify one of the plurality of discrete pieces is
      done without using tags..Iaddend.<br /> .Iadd.162. The method of claim 146,
      wherein comparing the offset value with the starting and ending point addresses
      recorded in the look-up table to identify one of the plurality of discrete pieces
      is done without reference to any tags which may be located in the textual source
      material..Iaddend.<br /> .Iadd.163. The method of claim 146, wherein comparing
      the offset value with the starting and ending point addresses recorded in the
      look-up table to identify one of the plurality of discrete pieces is done without
      reference to any hierarchical information which may be located in the textual
      source material..Iaddend.<br /> .Iadd.164. The method of claim 146, wherein
      the plurality of external reference materials comprises a plurality of text
      based external reference materials..Iaddend.<br /> .Iadd.165. The method of
      claim 146, wherein the plurality of external reference materials comprises a
      plurality of image based external reference materials..Iaddend.<br /> .Iadd.166.
      The method of claim 146, wherein the plurality of external reference materials
      comprises a plurality of graphic based external reference materials..Iaddend.<br
      /> .Iadd.167. The method of claim 146, wherein the plurality of external reference
      materials comprises a plurality of audio based external reference materials..Iaddend.<br
      /> .Iadd.168. The method of claim 146, wherein the plurality of external reference
      materials comprises a plurality of video based external reference materials..Iaddend.<br
      /> .Iadd.169. The method of claim 146, wherein at least one of the plurality
      of external reference materials is a combination of two or more of text based
      external reference material, image based external reference material, graphic
      based external reference material, audio based external reference material,
      and video based external reference material..Iaddend.<br /> .Iadd.170. The method
      of claim 146, wherein linking at least one of the plurality of discrete pieces
      is done manually..Iaddend.<br /> .Iadd.171. The method of claim 146, wherein
      linking at least one of the plurality of discrete pieces is done automatically..Iaddend.<br
      /> .Iadd.172. The method of claim 146, wherein the electronic database is an
      electronic relational database..Iaddend.<br /> .Iadd.173. The method of claim
      146, wherein the electronic database is an electronic file..Iaddend.<br /> .Iadd.174.
      The method of claim 146, wherein the electronic database is electronic text..Iaddend.<br
      /> .Iadd.175. The method of claim 146, wherein the beginning position address
      is a beginning location of the textual source material in the electronic database..Iaddend.<br
      /> .Iadd.176. The method of claim 175, wherein each starting point address is
      a starting location of at least one of the plurality of discrete pieces based
      upon the beginning location of the textual source material..Iaddend.<br /> .Iadd.177.
      The method of claim 175, wherein each ending point address is an ending location
      of at least one of the plurality of discrete pieces based upon the beginning
      location of the textual source material..Iaddend.<br /> .Iadd.178. The method
      of claim 146, further comprising: displaying the plurality of external reference
      materials corresponding to the identified one of the plurality of discrete pieces
      in a pop-up menu, prior to selecting one of the at least one of the plurality
      of external reference materials corresponding to the identified one of the plurality
      of discrete pieces..Iaddend.<br /> .Iadd.179. The method of claim 178, wherein
      the pop-up menu is displayed in the textual source material image next to the
      selected discrete portion..Iaddend.<br /> .Iadd.180. The method of claim 178,
      wherein the selected one of the plurality of external reference materials is
      selected using the pop-up menu..Iaddend.<br /> .Iadd.181. The method of claim
      178, wherein the pop-up menu displays labels for the plurality of external reference
      materials corresponding to the identified one of the plurality of discrete pieces..Iaddend.<br
      /> .Iadd.182. The method of claim 178, wherein the labels can each be selected
      in the pop-up menu to display the at least one of the plurality of external
      reference materials corresponding to the identified one of the plurality of
      discrete pieces..Iaddend.<br /> .Iadd.183. The method of claim 146, wherein
      the at least one of the plurality of external reference materials is a single
      word..Iaddend.<br /> .Iadd.184. The method of claim 146, wherein each of the
      plurality of external reference materials is a single word..Iaddend.","briefHtml":"(1)
      BACKGROUND OF THE INVENTION<br />(2)  1. Technical Field<br />(3)  The present
      invention relates to indexing displayed elements. More particularly, the present
      invention relates to a novel indexing scheme that is useful in such applications
      as learning a foreign language, for example a language based upon an ideographic
      alphabet, such as Japanese.<br />(4)  2. Description of the Prior Art<br />(5)  As
      the global economy turns the world''s many nations into what media visionary
      Marshall McLuhan referred to as a global village, the need to learn and use
      new or specialized information, such as a language other than one''s native
      language, becomes increasingly important. For example, there is a tremendous
      international demand for information related to Japan. Inside Japan, there is
      an abundance of information available in the Japanese language in numerous media
      forms. Japan has five national newspapers, seven major broadcasting networks,
      and several hundred book and magazine publishers. Japanese television focuses
      on the most obscure topics; and there are special interest magazines covering
      the full spectrum of Japanese society. Speakers of the Japanese language can
      find information on just about any topic imaginable. Unfortunately, outside
      of Japan this information is in short supply and the information that is available
      is primarily in English.<br />(6)  Individuals trying to learn about Japan are
      faced with the dilemma of either relying on English language sources or going
      through the pains of learning Japanese. English language information on Japan
      must go through the translation process. This results in time delays in obtaining
      necessary information, as well as in distortions in meaning. Furthermore, economics
      itself places restrictions on what information makes it''s way into English
      and what information does not. For general and introductory information on Japan,
      the English-based media is providing a valuable service. But for people who
      want to do more than scratch the surface, such information is far from sufficient.<br
      />(7)  A large number of non-native speakers have sought to study Japanese in
      universities or in professional language schools. In recent years, the interest
      level in Japanese among first year level college students has soared, such that
      it is rated second only to Spanish in some surveys. The number of people studying
      Japanese in the mid-1980''s in the United States was 50,000. This number has
      recently grown to 400,000 persons. But the study of Japanese language is plagued
      by the burdens of learning Kanji, the ideographic alphabet in which Japanese
      is written. Thus, the standing room only first-year Japanese language class
      in many universities soon becomes the almost private lesson-like third year
      class due to student attrition resulting from the difficulty of mastering Kanji.<br
      />(8)  The situation in Japan for foreigners is not much more encouraging. The
      cost of living in Japan poses a major barrier for both business people and students.
      There are currently over 300,000 United States citizens working or studying
      in Japan. But in recent years, foreign companies have been cutting their foreign
      staff. This, in part, has been in response to the enormous expense associated
      with maintaining them in Japan; but it is also a statement about the effectiveness
      of a large percentage of these people, who typically possess no Japanese language
      skills or background. Nevertheless, the necessity to do business in Japan is
      clear to most major United States companies, and access to Japan''s inside information
      is critical to the success of such companies.<br />(9)  The situation in Japanese
      universities is also discouraging. There are currently about 30,000 foreign
      students in Japanese universities, compared to a total of over 300,000 foreign
      students studying in the United States. Ninety percent of the foreign students
      in Japan are from Asia, while there are less than 1,000 students in Japan from
      the United States. The cost of living and housing again contribute greatly to
      this disparity, but the language barrier must be seen as the prime hurdle that
      causes students to abandon the attempt to explore Japan. In the future, the
      desirability for students and researchers to work in Japan should increase due
      to the growth of &quot;science cities&quot; and the increase in the hiring of
      foreign researchers by Japanese corporations. The burden of studying Japanese,
      however, remains.<br />(10)  In total there are over 60,000 people enrolled
      in Japanese language programs in Japan; and according to the Japan Foundation,
      there are approximately 1,000,000 Japanese language students worldwide, with
      a total of over 8,200 Japanese language instructors in 4,000 institutes. However,
      without a more effective and productive methodology for reading Japanese and
      for building Japanese language vocabulary, the level and breadth of the information
      making its way to non-natives should not be expected to improve.<br />(11)  The
      foregoing is but one example of the many difficulties one is faced with when
      acquiring or using difficult or unfamiliar material. The first challenge anyone
      reading a difficult text, is faced with is the issue of character recognition
      and pronunciation. For example, a student of the Japanese language spends many
      frustrating hours counting character strokes and looking up characters in a
      dictionary. Challenges such as this are the primary reason so many people give
      up on Japanese after a short trial period. It is also the reason that people
      who continue to pursue the language are unable to build an effective vocabulary.<br
      />(12)  Knowing the &quot;yomi&quot; or pronunciation or reading of a word is
      essential to memorize and assimilate the word into one''s vocabulary. This allows
      the student to read a word in context and often times deduce its meaning. But
      in many cases, the word may be entirely new to the reader, or it may be a usage
      that the reader has never seen. Looking up the word in the dictionary or asking
      a native speaker are the only options available to a student. Once the yomi
      for the word is known, i.e. the meaning and understanding of the word in context,
      the final challenge is to memorize the word and make it a part of a usable vocabulary.<br
      />(13)  The sheer number of characters in ideographic alphabets, such as Kanji,
      presents unique challenges for specifying and identifying individual characters.<br
      />(14)  Various schemes have been proposed and descriptions can be found in
      the literature for the entry of Kanji characters into computers and the like.<br
      />(15)  See, for example, Y. Chu, Chinese/Kanji Text and Data Processing, IEEE
      Computer (January 1985); J. Becker, Typing Chinese, Japanese, and Korean, IEEE
      Computer (January 1985); R. Matsuda, Processing Information in Japanese, IEEE
      Computer (January 1985); R. Walters, Design of a Bitmapped Multilingual Workstation,
      IEEE Computer (February 1990); and J. Huang, The Input and Output of Chinese
      and Japanese Characters, IEEE Computer (January 1985).<br />(16)  And, see J.
      Monroe, S. Roberts, T. Knoche, Method and Apparatus for Processing Ideographic
      Characters, U.S. Pat. No. 4,829,583 (9 May 1989), in which a specific sequence
      of strokes is entered into a 9.times.9 matrix, referred to as a training square.
      This sequence is matched to a set of possible corresponding ideographs. Because
      the matrix senses stroke starting point and stroke sequences based on the correct
      writing of the ideograph to be identified, this system cannot be used effectively
      until one has mastered the writing of the ideographic script. See, also G. Kostopoulos,
      Composite Character Generator, U.S. Pat. No. 4,670,841 (2 Jun. 1987); A. Carmon,
      Method and Apparatus For Selecting, Storing and Displaying Chinese Script Characters,
      U.S. Pat. No. 4,937,745 (26 Jun. 1990); and R. Thomas, H. Stohr, Symbol Definition
      Apparatus, U.S. Pat. No. 5,187,480 (16 Feb. 1993).<br />(17)  A text revision
      system is disclosed in R. Sakai, N, Kitajima, C. Oshima, Document Revising System
      For Use With Document Reading and Translation System, U.S. Pat. No. 5,222,160
      (22 Jun. 1993), in which a foreigner having little knowledge of Japanese can
      revise misrecognized imaged characters during translation of the document from
      Japanese to another language. However, the system is provided for commercial
      translation services and not intended to educate a user in the understanding
      or meaning of the text.<br />(18)  Thus, although much attention has been paid,
      for example, to the writing, identification, and manipulation of ideographic
      characters, none of these approaches are concerned with providing a language
      learning system. The state of the art for ideographic languages, such as Japanese,
      does not provide an approach to learning the language that meets the four primary
      challenges discussed above, i.e. reading the language (for example, where an
      ideographic alphabet is used), comprehending the meaning of a particular word
      encountered while reading the language, understanding the true meaning of the
      word within the context that the word is used, and including the word in a personal
      dictionary to promote long term retention of the meaning of the word. A system
      that applies this approach to learning a language would be a significant advance
      in bridging the gap between the world''s diverse cultures because of the increased
      understanding that would result from an improved ability to communicate with
      one another. Such system would only be truly useful if it were based upon an
      indexing scheme that allowed meaningful manipulation and display of the various
      elements of the language.<br />(19) SUMMARY OF THE INVENTION<br />(20)  The
      invention provides a unique system for indexing displayed elements and finds
      ready application, for example in a language learning system that enhances and
      improves the way non-natives read foreign languages, for example the way a native
      English speaker reads Japanese. The language learning system provides a more
      effective way for people to read and improve their command of the foreign language,
      while at the same time communicating insightful and relevant cultural, social,
      and economic information about the country.<br />(21)  The learning model used
      by the language learning system is straightforward and is based upon methods
      that are familiar to most learners of foreign languages. The system addresses
      the four challenges of reading a foreign language, such as Japanese: i.e. reading
      the foreign word or character, such as Kanji in the case of a language having
      an ideographic alphabet, such as Japanese; comprehending the meaning of the
      word; understanding the word in context; and including the word in a personal
      vocabulary.<br />(22)  The exemplary embodiment of the invention includes one
      or more foreign language books that are read on an electronic display of a personal
      computer. English word references are available for each word in such books.
      The definitions of such words are derived from well known foreign language dictionaries.
      With regard to the Japanese language, the system saves significant amounts of
      time and effort by eliminating the need for the user to look up Japanese characters
      in a Kanji dictionary.<br />(23)  When one uses the system, the pronunciations
      or readings (`yomi`) for all words are immediately viewable in a pop-up window
      without accessing a disk based database, for example by clicking a mouse on
      a selected word or phrase. In the same pop-up window, the system provides an
      English reference to any word that is also selected by clicking on the selected
      word or phrase. The system provides extensive notes for difficult phrases and
      words not normally found in a dictionary, and includes a relational database
      designed for managing and studying words. This allows a user to build a personal
      database of words that he would like to master. Words may also be entered from
      other sources that are currently in paper or other electronic formats. A unique
      indexing scheme allows word-by-word access to any of several external multi-media
      references.","backgroundTextHtml":".Iadd.Note: More than one reissue patent
      application has been filed forthe reissue of U.S. Pat. No. 5,822,720. The reissue
      patent applications are U.S. Reissue patent application Ser. No. 11/064,519,
      filed Feb. 24, 2005, and issued as U.S. Pat. No. Re. 40,731, and the present
      U.S. Reissue patent application Ser. No. 12/480,556, filed Jun. 8, 2009, which
      is a continuation reissue application of U.S. Reissue patent application Ser.
      No. 11/064,519 filed Feb. 24, 2005 now U.S. Pat. No. Re 40,731..Iaddend. \n\n
      This is a continuation of application Ser. No. 08/197,157 filed Feb. 16,\n1994
      now abandoned.","subHeadingM0Html":null,"subHeadingM1Html":null,"subHeadingM2Html":null,"subHeadingM3Html":null,"subHeadingM4Html":null,"subHeadingM5Html":null,"subHeadingM6Html":null,"usClassIssued":"704/3","issuedUsDigestRefClassifi":null,"datePublYear":"2012","applicationYear":"2009","pfDerwentWeekYear":null,"pfApplicationYear":null,"pfPublYear":null,"reissueApplNumber":["12480556"],"abstractHeader":null,"abstractedPublicationDerwent":null,"affidavit130BFlag":null,"affidavit130BText":null,"applicantGroup":null,"applicantHeader":null,"applicationFilingDateInt":20090608,"applicationFilingDateIntKwicHits":null,"applicationRefFilingType":null,"applicationReferenceGroup":null,"applicationSeriesAndNumber":"12480556","applicationSeriesCode":"12","assignee1":null,"assigneeDescriptiveText":["N/A"],"patentAssigneeTerms":null,"associateAttorneyName":null,"attorneyName":null,"biologicalDepositInformation":null,"applicationType":null,"unlinkedDerwentRegistryNumber":null,"unlinkedRingIndexNumbersRarerFragments":null,"claimStatement":"We
      claim:","claimsTextAmended":null,"continuedProsecutionAppl":null,"cpcAdditionalLong":null,"cpcCisClassificationOrig":null,"cpcCombinationClassificationOrig":null,"cpcInventive":["G09B19/06
      20130101","G09B5/065 20130101"],"cpcInventiveCurrentDateKwicHits":null,"cpcAdditional":null,"cpcAdditionalCurrentDateKwicHits":null,"cpcOrigClassificationGroup":null,"curIntlPatentClassificationGroup":null,"curUsClassificationUsPrimaryClass":null,"curUsClassificationUsSecondaryClass":null,"customerNumber":null,"depositAccessionNumber":null,"depositDescription":null,"derwentClassAlpha":null,"designatedstatesRouteGroup":null,"docAccessionNumber":null,"drawingDescription":null,"editionField":null,"exchangeWeek":null,"exemplaryClaimNumber":["17"],"familyIdentifierOrig":null,"fieldOfSearchCpcClassification":null,"fieldOfSearchCpcMainClass":null,"fieldOfSearchIpcMainClass":null,"fieldOfSearchIpcMainClassSubclass":null,"fieldOfSearchSubclasses":["706-708;758;999.003","1;9;10","255;856","157;160"],"foreignRefGroup":["EP
      0 093 250 19831100 cited by other","EP 0 725 353 19960700 cited by other","EP
      0 840 240 19980500 cited by other","JP 03-174653 19910700 cited by other","JP
      04-220768 19920800 cited by other","JP 04-288674 19921000 cited by other","JP
      04-320530 19921100 cited by other","JP 04-320551 19921100 cited by other","JP
      05-012096 19930100 cited by other","JP 05-128157 19930500 cited by other","WO
      95/04974 19950200 cited by other"],"foreignRefPubDate":["19831100","19960700","19980500","19910700","19920800","19921000","19921100","19921100","19930100","19930500","19950200"],"foreignRefPubDateKwicHits":["19831100","19960700","19980500","19910700","19920800","19921000","19921100","19921100","19930100","19930500","19950200"],"foreignRefCitationClassification":["N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A"],"foreignRefPatentNumber":["0
      093 250","0 725 353","0 840 240","03-174653","04-220768","04-288674","04-320530","04-320551","05-012096","05-128157","95/04974"],"foreignRefCitationCpc":null,"foreignRefCountryCode":["EP","EP","EP","JP","JP","JP","JP","JP","JP","JP","WO"],"iceXmlIndicator":"Y","internationalClassificationHeader":null,"internationalClassificationInformationalGroup":null,"intlPubClassificationGroup":["20060101
      A G06F G06F17/30 F I B US H 20120904","20060101 A G06F G06F17/28 L I B US H
      20120904"],"intlPubClassificationNonInvention":null,"inventorCitizenship":null,"inventorCorrection":null,"inventorDeceased":null,"inventorStreetAddress":["N/A","N/A"],"inventorText":["N/A","N/A"],"jpoFiClassification":null,"legalRepresentativeCity":null,"legalRepresentativeCountry":"[]","legalRepresentativeName":null,"legalRepresentativePostcode":null,"legalRepresentativeState":null,"legalRepresentativeStreetAddress":null,"legalRepresentativeText":null,"messengerDocsFlag":null,"newRecordPatentDerwent":null,"numberOfClaims":"168","numberOfDrawingSheets":"5","numberOfFigures":"5","numberOfPagesInSpecification":null,"numberOfPagesOfSpecification":null,"objectContents":null,"objectDescription":null,"parentDocCountry":null,"parentGrantDocCountry":null,"patentBibliographicHeader":null,"pctOrRegionalPublishingSerial":null,"pfDerwentWeekNum":null,"principalAttorneyName":null,"priorityApplicationCountry":null,"priorityClaimsCountry":null,"priorityNumberDerived":null,"publicationIssueNumber":null,"refCitedPatentDocNumber":null,"refCitedPatentDocDate":null,"refCitedPatentDocKindCode":null,"referenceCitedCode":null,"referenceCitedGroup":null,"referenceCitedSearchPhase":null,"referenceCitedText":null,"registrationNumber":null,"reissueApplCountry":["US"],"reissueParentKind":null,"reissueParentNumber":["5822720"],"reissueParentPubCountry":["US"],"reissuePatentGroup":["US
      08676890 19960708 GRANTED US 5822720 19981013 US 12480556"],"reissuePatentParentStatus":["GRANTED"],"reissuedPatentApplCountry":["US"],"reissuedPatentApplKind":null,"reissuedPatentApplNumber":["08676890"],"relatedApplChildPatentCountry":["US","US"],"relatedApplChildPatentName":null,"relatedApplChildPatentNumber":["08676890","11064519"],"relatedApplCountryCode":null,"relatedApplParentGrantPatentKind":null,"relatedApplParentGrantPatentName":null,"relatedApplParentPatentKind":null,"relatedApplParentPatentName":null,"relatedApplParentPctDoc":null,"relatedApplParentStatusCode":["ABANDONED"],"relatedApplPatentNumber":["Re.
      40731"],"relatedApplRelatedPub":null,"relatedApplTypeOfCorrection":null,"rule47Flag":null,"selectedDrawingCharacter":null,"selectedDrawingFigure":null,"statutoryInventionText":null,"termOfExtension":null,"termOfPatentGrant":null,"titleTermsData":null,"additionalIndexingTerm":null,"applicationYearSearch":"2009","pfApplicationYearSearch":null,"assigneeCountry":["US"],"certOfCorrectionFlag":null,"citedPatentLiteratureAddressInformation":null,"citedPatentLiteratureClassificationIpc":null,"citedPatentLiteratureOrganizationName":null,"citedPatentLiteratureRefNumber":null,"crossReferenceNumber":null,"country":"US","cpiManualCodes":null,"cpiSecondaryAccessionNumber":null,"curIntlPatentAllClassificationLong":null,"currentUsOriginalClassificationLong":null,"datePublSearch":"2012-09-04T00:00:00.000+00:00","datePublYearSearch":"2012","epiManualCodes":null,"fieldOfSearchMainClassNational":["707","704","715","345"],"inventorCountry":["US","US"],"ipcAllMainClassification":["G06F"],"issuedUsClassificationFull":["345/157","715/255","704/10","707/758","704/9","345/160","704/1","707/999.003","715/856","704/3"],"issuedUsDigestRefClassification":["345/157","345/160","704/1","704/9","704/10","715/856","715/255","707/999.003","707/758"],"jpoFiCurrentAdditionalClassification":null,"jpoFiCurrentInventiveClassification":null,"legalFirmName":["Wilmer
      Cutler Pickering Hale and Dorr LLP"],"locarnoMainClassification":null,"nonCpiSecondaryAccessionNumber":null,"objectId":null,"otherRefPub":["Allen,
      &quot;Introduction to Natural Language Understanding&quot;, Natural Language
      Understanding, Chapter 1, p. 1-19, The Benjamin/Cummings Publishing Company,
      Inc., 1988. cited by other\n<br />Almasi, et al., Highly Parallel Computing
      2.sup.nd Edition, The Benjamin/Cummings Publishing Company, Inc.,Chapter 2,
      p. 38-51 and 87-95, 1994. cited by other\n<br />Anonymous, &quot;Hypertext Method&quot;,
      IBM Technical Bulletin, 1 page, Oct. 1989. cited by other\n<br />Anonymous,
      Microsoft Corporation, Microsoft Word 97, screen printouts, pp. 1-4,1997. cited
      by other\n<br />Baez, et al., &quot;Portable Translator&quot;, IBM Technical
      Bulletin, vol. 37, No. 11, p. 185-188, Nov. 1994. cited by other\n<br />Brookshear,
      Introduction to &quot;Computer Science, An Overview&quot;, Benjamin/Cummings
      Publishing, p. 17, 1988. cited by other\n<br />Cohen, et al., &quot;Method for
      Automatic Analysis of Meter in (both) Poetry and Prose&quot;, IBM Technical
      Bulletin, vol. 32, No. 9B, p. 224-226, Feb. 1990. cited by other\n<br />Dunnington,
      et al., &quot;Methodology and Apparatus for Translation of Text to Sign Language
      Images&quot;, vol. 37, No. 04A, p. 229-230, Apr. 1994. cited by other\n<br />Eisen,
      et al., &quot;Multilingual Multimedia Hyperlink Network Design&quot;, IBM Technical
      Bulletin, vol. 36, No. 09B, p. 471-472, Sep. 1993. cited by other\n<br />Eisen,
      et al., &quot;OS/2 Presentation Manager Controls Enabled for Hypermedia Link
      Markers&quot;, IBM Technical Bulletin, vol. 34, No. 10B, p. 433-434, Mar. 1992.
      cited by other\n<br />Elliott, &quot;Tuning up HyperCard''s Database Engine&quot;,
      Supplement to Dr. Dobb''s Journal, p. 39s-41s, Apr. 1993. cited by other\n<br
      />Foley, et al., Introduction to &quot;Computer Graphics--Principles and Practice
      2.sup.nd Ed. in C&quot;, Addison-Wesley Publishing Company, Inc., p. 1-9, 1996.
      cited by other\n<br />Fuger et al., Proceedings of The First IEEE Conference
      on Evolutionary Computation, IEEE World Congress on Computational Intelligence,
      Walt Disney World Dolphin Hotel, Orlando, FL, vol. I, p. 229-234, Jun. 27-Jun.
      29, 1994. cited by other\n<br />Germain, et al., &quot;Hypertext Document Update&quot;,
      IBM Technical Bulletin, vol. 34, No. 8, p. 22-23, Jan. 1992. cited by other\n<br
      />Glinert, A Pumped-Up Publishing Pro, Computer Shopper, Computer Select, p.
      462, Apr. 1997. cited by other\n<br />Goodman, Web Documents Without HTML, Computer
      Select, Computer Shopper, Apr. 1997. cited by other\n<br />Goose, et al., &quot;Unifying
      Distributed Processing and Open Hypermedia through a Heterogeneous Communication
      Model&quot;, University of Southampton, Technical Report No. 95-6, p. 1-12,
      Nov. 1995. cited by other\n<br />Marshall, Acrobat, Common Ground Extend Reach
      Beyond Document Viewing, InfoWorld, Computer Select, Apr. 21, 1997, p. 105.
      cited by other\n<br />Montana, &quot;Automated Parameter Tuning for Interpretation
      of Synthetic Images&quot;, Handbook of Genetic Algorithms, edited by Lawrence
      Davis, Chapter 19, p. 282-311, 1991. cited by other\n<br />Nelson, FrenchNow
      3.0 Language-Learning Tool, Macworld Reviews, p. 83, Dec. 1995. cited by other\n<br
      />Takehi, &quot;Implementing Memory Efficient Hypertext in Online Manual Tool&quot;,
      IBM Technical Bulletin, vol. 33, No. 11, p. 259-263, Apr. 1991. cited by other\n<br
      />Weibel, Publish to Paper and the Web, Computer Select, Dec. 1996, PC/Computing,
      p. 130. cited by other\n<br />Winston, et al., Finding Patterns in Images, LISP
      3.sup.rd Edition, Chapter 31, p. 456-483, Addison-Wesley Publishing Company,
      1989. cited by other\n<br />Yankelovich, et al., &quot;Reading and Writing the
      Electronic Book&quot;, Computer, vol. 18, No. 10, p. 15-30, Oct. 1985. cited
      by other\n<br />Addressmate Automatic Envelope Addressing Program, User''s Manual
      (1991). cited by other\n<br />User Manual for AddressMate and AddressMate Plus
      by AddressMate Software (1994-1995). cited by other\n<br />Apple Internet Address
      Detector User''s Manual, Aug. 28, 1997. cited by other\n<br />Microsoft Word
      97 Help File entitled Automatically check spelling and grammar as you type (1997).
      cited by other\n<br />Developer''s Guide to Apple Data Detectors, Dec. 1997.
      cited by other\n<br />Novell GroupWise User''s Guide for Windows 16-Bit, Version
      5.2, 1993, MS 125993, Novell, Inc., Orem, Utah. cited by other (1993). cited
      by other\n<br />Haak, Personal Computing--WordPerfect News: WordPerfect for
      Windows 7.0; A Sneak Preview, Colorado State University, Vector Academic Computing
      &amp; Network Services, vol. 13, No. 3, Jan./Feb. 1996. cited by other\n<br
      />Thistlewaite, &quot;Automatic Construction and Management of Large Open Webs&quot;,
      Information Processing and Management, vol. 33, pp. 161-173 (published Mar.
      1997). cited by other\n<br />Delivery and Retrieval Technology, Electronic Delivery,
      Document Management, Catalog Publishing, Page Layout, Hardware, Seybold Seminars
      Boston--Special Report, vol. 2, No. 8, Apr. 1994. cited by other\n<br />Seybold
      Seminars and Imprinta ''92, part 1: RIPs and Recorders, Seybold Report on Publishing
      Systems, vol. 21, No. 12, p. 10, 1992. cited by other\n<br />Order re: Construction
      of Claim 8 of United States Patent No. 5,822,720 in the matter of Sentius Corporation
      v. Flyswat, Inc. in the United States District Court for the Northern District
      of California dated Apr. 4, 2002. cited by other\n<br />Order in the matter
      of Sentius Corporation v. Flyswat, Inc. in the United States District Court
      for the Northern District of California dated Aug. 5, 2002. cited by other\n<br
      />A sales brochure from Transparent Language of Hollis, NH about the Transparent
      Language System software, no date. cited by other\n<br />A sample screen from
      the software of Transparent Language of Hollis, NH, no date. cited by other\n<br
      />"],"pageNumber":null,"patentAssigneeCode":null,"patentAssigneeNameTotal":null,"patentFamilyDate":null,"patentFamilyDocNumber":null,"patentFamilyKind":null,"patentFamilyKindCode":null,"patentFamilyLanguage":null,"patentFamilyName":null,"patentNumberOfLocalApplication":null,"pct102eDate":null,"pct371c124Date":null,"pct371c124DateKwicHits":null,"pctFilingDate":null,"pctFilingDateKwicHits":null,"pctFilingDocCountryCode":null,"pctFilingKind":null,"pctFilingNumber":null,"pctName":null,"pctOrRegionalPublishingCountry":null,"pctOrRegionalPublishingKind":null,"pctOrRegionalPublishingName":null,"pctOrRegionalPublishingText":null,"pctPubDate":null,"pctPubDateKwicHits":null,"pctPubDocIdentifier":null,"pctPubNumber":null,"pfApplicationDateSearch":null,"pfApplicationType":null,"pfDerwentWeekDate":null,"pfPublDateSearch":null,"pfPublDateSearchKwicHits":null,"pfPublYearSearch":null,"polymerIndexingCodes":null,"polymerMultipunchCodeRecordNumber":null,"polymerMultipunchCodes":null,"priorPublishedDocCountryCode":null,"priorPublishedDocDate":null,"priorPublishedDocDateKwicHits":null,"priorPublishedDocIdentifier":null,"priorPublishedDocKindCode":null,"priorPublishedDocNumber":null,"priorityApplYear":null,"priorityApplicationDate":null,"priorityClaimsDateSearch":null,"priorityClaimsDocNumber":null,"priorityPatentDid":null,"priorityPatentNumber":null,"ptabCertFlag":null,"pubRefCountryCode":null,"pubRefDocNumber":"RE43633","pubRefDocNumber1":"RE043633","publicationData":null,"recordPatentNumber":null,"reexaminationFlag":null,"refCitedOthers":null,"refCitedPatentDocCountryCode":null,"refCitedPatentDocName":null,"refCitedPatentRelevantPassage":null,"reissueParentIssueDate":["1998-10-13T00:00:00.000+00:00"],"reissuedPatentApplFilingDate":["1996-07-08T00:00:00.000+00:00"],"relatedAccessionNumbers":null,"relatedApplChildPatentDate":null,"relatedApplFilingDateKwicHits":null,"relatedApplNumber":["11064519","08197157"],"relatedApplPatentIssueDate":null,"relatedApplPatentIssueDateKwicHits":null,"relatedDocumentKindCode":null,"securityLegend":null,"sequenceCwu":null,"sequenceListNewRules":null,"sequenceListOldRules":null,"sequencesListText":null,"standardTitleTerms":null,"supplementalExaminationFlag":null,"usBotanicLatinName":null,"usBotanicVariety":null,"usRefClassification":["N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A","N/A"],"usRefCpcClassification":null,"usRefGroup":["US
      3872448 A 19750300 Mitchell, Jr. et al. cited by other","US 4136395 A 19790100
      Kolpek et al. cited by other","US 4318184 A 19820300 Millett et al. cited by
      other","US 4384288 A 19830500 Walton cited by other","US 4651300 A 19870300
      Suzuki et al. cited by other","US 4674065 A 19870600 Lange et al. cited by other","US
      4689768 A 19870800 Heard et al. cited by other","US 4742481 A 19880500 Yoshimura
      cited by other","US 4773009 A 19880900 Kucera et al. cited by other","US 4817050
      A 19890300 Komatsu et al. cited by other","US 4837797 A 19890600 Freeny, Jr.
      cited by other","US 4864501 A 19890900 Kucera et al. cited by other","US 4868743
      A 19890900 Nishio cited by other","US 4868750 A 19890900 Kucera et al. cited
      by other","US 4887212 A 19891200 Zamora et al. cited by other","US 4893270 A
      19900100 Beck et al. cited by other","US 4914586 A 19900400 Swinehart et al.
      cited by other","US 4945476 A 19900700 Bodick et al. cited by other","US 4958283
      A 19900900 Tawara et al. cited by other","US 4980855 A 19901200 Kojima cited
      by other","US 4982344 A 19910100 Jordan cited by other","US 4994966 A 19910200
      Hutchins cited by other","US 5020019 A 19910500 Ogawa cited by other","US 5065315
      A 19911100 Garcia cited by other","US 5088052 A 19920200 Spielman et al. cited
      by other","US 5128865 A 19920700 Sadler cited by other","US 5146439 A 19920900
      Jachmann et al. cited by other","US 5146552 A 19920900 Cassorla et al. cited
      by other","US 5151857 A 19920900 Matsui cited by other","US 5157606 A 19921000
      Nagashima cited by other","US 5204947 A 19930400 Bernstein et al. cited by other","US
      5214583 A 19930500 Miike et al. cited by other","US 5218697 A 19930600 Chung
      cited by other","US 5222160 A 19930600 Sakai et al. cited by other","US 5226117
      A 19930700 Miklos cited by other","US 5233513 A 19930800 Doyle cited by other","US
      5241671 A 19930800 Reed et al. cited by other","US 5253362 A 19931000 Nolan
      et al. cited by other","US 5256067 A 19931000 Gildea et al. cited by other","US
      5267155 A 19931100 Buchanan et al. cited by other","US 5289376 A 19940200 Yokogawa
      cited by other","US 5297249 A 19940300 Bernstein et al. cited by other","US
      5303151 A 19940400 Neumann cited by other","US 5319711 A 19940600 Servi cited
      by other","US 5329446 A 19940700 Kugimiya et al. cited by other","US 5331555
      A 19940700 Hashimoto et al. cited by other","US 5337233 A 19940800 Hofert et
      al. cited by other","US 5349368 A 19940900 Takeda et al. cited by other","US
      5351190 A 19940900 Kondo cited by other","US 5361202 A 19941100 Doue cited by
      other","US 5367621 A 19941100 Cohen et al. cited by other","US 5375200 A 19941200
      Dugan et al. cited by other","US 5377323 A 19941200 Vasudevan cited by other","US
      5392386 A 19950200 Chalas cited by other","US 5404435 A 19950400 Rosenbaum cited
      by other","US 5404506 A 19950400 Fujisawa et al. cited by other","US 5408655
      A 19950400 Oren et al. cited by other","US 5416901 A 19950500 Torres cited by
      other","US 5418942 A 19950500 Krawchuk et al. cited by other","US 5434974 A
      19950700 Loucks et al. cited by other","US 5438655 A 19950800 Richichi et al.
      cited by other","US 5455945 A 19951000 Vanderdrift cited by other","US 5459860
      A 19951000 Brunett et al. cited by other","US 5491783 A 19960200 Douglas et
      al. cited by other","US 5491784 A 19960200 Douglas et al. cited by other","US
      5500859 A 19960300 Sharma et al. cited by other","US 5506984 A 19960400 Miller
      cited by other","US 5515534 A 19960500 Chuah et al. cited by other","US 5517409
      A 19960500 Ozawa et al. cited by other","US 5530852 A 19960600 Meske, Jr. et
      al. cited by other","US 5530853 A 19960600 Schell et al. cited by other","US
      5537132 A 19960700 Teraoka et al. cited by other","US 5537590 A 19960700 Amado
      cited by other","US 5541836 A 19960700 Church et al. cited by other","US 5546447
      A 19960800 Skarbo et al. cited by other","US 5546529 A 19960800 Bowers et al.
      cited by other","US 5564046 A 19961000 Nemoto et al. cited by other","US 5576955
      A 19961100 Newbold et al. cited by other","US 5581460 A 19961200 Kotake et al.
      cited by other","US 5583761 A 19961200 Chou cited by other","US 5603025 A 19970200
      Tabb et al. cited by other","US 5606712 A 19970200 Hidaka cited by other","US
      5608900 A 19970300 Dockter et al. cited by other","US 5617488 A 19970400 Hong
      et al. cited by other","US 5629981 A 19970500 Nerlikar cited by other","US 5640565
      A 19970600 Dickinson cited by other","US 5644740 A 19970700 Kiuchi cited by
      other","US 5646416 A 19970700 Van De Velde cited by other","US 5649222 A 19970700
      Mogilevsky cited by other","US 5657259 A 19970800 Davis et al. cited by other","US
      5659676 A 19970800 Redpath cited by other","US 5666502 A 19970900 Capps cited
      by other","US 5694523 A 19971200 Wical cited by other","US 5708804 A 19980100
      Goodwin et al. cited by other","US 5708822 A 19980100 Wical cited by other","US
      5708825 A 19980100 Sotomayor cited by other","US 5724593 A 19980300 Hargrave,
      III et al. cited by other","US 5724597 A 19980300 Cuthbertson et al. cited by
      other","US 5727129 A 19980300 Barrett et al. cited by other","US 5729741 A 19980300
      Liaguno et al. cited by other","US 5732229 A 19980300 Dickinson cited by other","US
      5740252 A 19980400 Minor et al. cited by other","US 5745360 A 19980400 Leone
      cited by other","US 5745908 A 19980400 Anderson et al. cited by other","US 5754847
      A 19980500 Kaplan et al. cited by other","US 5754857 A 19980500 Gadol cited
      by other","US 5761436 A 19980600 Nielsen cited by other","US 5761656 A 19980600
      Ben-Shachar cited by other","US 5761659 A 19980600 Bertoni cited by other","US
      5761689 A 19980600 Rayson cited by other","US 5764906 A 19980600 Edelstein et
      al. cited by other","US 5778363 A 19980700 Light cited by other","US 5781189
      A 19980700 Holleran et al. cited by other","US 5781900 A 19980700 Shoji et al.
      cited by other","US 5781904 A 19980700 Oren et al. cited by other","US 5787386
      A 19980700 Kaplan et al. cited by other","US 5793972 A 19980800 Shane cited
      by other","US 5794050 A 19980800 Dahlgren et al. cited by other","US 5794228
      A 19980800 French et al. cited by other","US 5794259 A 19980800 Kikinis cited
      by other","US 5799267 A 19980800 Siegel cited by other","US 5799302 A 19980800
      Johnson et al. cited by other","US 5802559 A 19980900 Bailey cited by other","US
      5805886 A 19980900 Skarbo et al. cited by other","US 5805911 A 19980900 Miller
      cited by other","US 5806079 A 19980900 Rivette et al. cited by other","US 5815830
      A 19980900 Anthony cited by other","US 5819092 A 19981000 Ferguson et al. cited
      by other","US 5822539 A 19981000 Van Hoff cited by other","US 5822720 A 19981000
      Bookman et al. cited by other","US 5826257 A 19981000 Snelling, Jr. cited by
      other","US 5832496 A 19981100 Anand et al. cited by other","US 5835059 A 19981100
      Nadel et al. cited by other","US 5835089 A 19981100 Skarbo et al. cited by other","US
      5845238 A 19981200 Fredenburg cited by other","US 5855007 A 19981200 Jovicic
      et al. cited by other","US 5859636 A 19990100 Pandit cited by other","US 5860073
      A 19990100 Ferrel et al. cited by other","US 5862325 A 19990100 Reed et al.
      cited by other","US 5864848 A 19990100 Horvitz et al. cited by other","US 5870702
      A 19990200 Yamabana cited by other","US 5870746 A 19990200 Knutson cited by
      other","US 5873107 A 19990200 Borovoy et al. cited by other","US 5875443 A 19990200
      Nielsen cited by other","US 5875446 A 19990200 Brown et al. cited by other","US
      5878421 A 19990300 Ferrel et al. cited by other","US 5884247 A 19990300 Christy
      cited by other","US 5884302 A 19990300 Ho cited by other","US 5884309 A 19990300
      Vanechanos, Jr. cited by other","US 5892919 A 19990400 Nielsen cited by other","US
      5893093 A 19990400 Wills cited by other","US 5895461 A 19990400 De La Huerga
      et al. cited by other","US 5896321 A 19990400 Miller et al. cited by other","US
      5896533 A 19990400 Ramos et al. cited by other","US 5897475 A 19990400 Pace
      et al. cited by other","US 5900004 A 19990500 Gipson cited by other","US 5905866
      A 19990500 Nakabayashi et al. cited by other","US 5905991 A 19990500 Reynolds
      cited by other","US 5907838 A 19990500 Miyasaka et al. cited by other","US 5913214
      A 19990600 Madnnick et al. cited by other","US 5920859 A 19990700 Li cited by
      other","US 5924090 A 19990700 Krellenstein cited by other","US 5926808 A 19990700
      Evans et al. cited by other","US 5930471 A 19990700 Milewski et al. cited by
      other","US 5940843 A 19990800 Zucknovich et al. cited by other","US 5946647
      A 19990800 Miller et al. cited by other","US 5953718 A 19990900 Wical cited
      by other","US 5963205 A 19991000 Sotomayor cited by other","US 5963940 A 19991000
      Liddy et al. cited by other","US 5963950 A 19991000 Nielsen et al. cited by
      other","US 5970505 A 19991000 Ebrahim cited by other","US 5974413 A 19991000
      Beauregard et al. cited by other","US 5983171 A 19991100 Yokoyama et al. cited
      by other","US 5987403 A 19991100 Sugimura cited by other","US 5987460 A 19991100
      Niwa et al. cited by other","US 5987475 A 19991100 Murai cited by other","US
      5999938 A 19991200 Bliss et al. cited by other","US 6006218 A 19991200 Breese
      et al. cited by other","US 6006242 A 19991200 Poole et al. cited by other","US
      6014677 A 20000100 Hayashi et al. cited by other","US 6021403 A 20000200 Horvitz
      et al. cited by other","US 6022222 A 20000200 Guinan cited by other","US 6026088
      A 20000200 Rostoker et al. cited by other","US 6026398 A 20000200 Brown et al.
      cited by other","US 6028605 A 20000200 Conrad et al. cited by other","US 6031537
      A 20000200 Hugh cited by other","US 6038573 A 20000300 Parks cited by other","US
      6047252 A 20000400 Kumano et al. cited by other","US 6055531 A 20000400 Bennett
      et al. cited by other","US 6061675 A 20000500 Wical cited by other","US 6067565
      A 20000500 Horvitz cited by other","US 6076088 A 20000600 Paik et al. cited
      by other","US 6085201 A 20000700 Tso cited by other","US 6085226 A 20000700
      Horvitz cited by other","US 6092074 A 20000700 Rodkin et al. cited by other","US
      6094649 A 20000700 Bowen et al. cited by other","US 6108674 A 20000800 Murakami
      et al. cited by other","US 6122647 A 20000900 Horowitz et al. cited by other","US
      6126306 A 20001000 Ando cited by other","US 6128635 A 20001000 Ikeno cited by
      other","US 6137911 A 20001000 Zhilyaev cited by other","US 6151624 A 20001100
      Teare et al. cited by other","US 6154738 A 20001100 Call cited by other","US
      6178434 B1 20010100 Saitoh cited by other","US 6182133 B1 20010100 Horvitz cited
      by other","US 6185550 B1 20010200 Snow et al. cited by other","US 6185576 B1
      20010200 McIntosh cited by other","US 6233570 B1 20010500 Horvits et al. cited
      by other","US 6260035 B1 20010700 Horvitz et al. cited by other","US 6262730
      B1 20010700 Horvitz et al. cited by other","US 6272505 B1 20010800 De La Huerga
      cited by other","US 6289342 B1 20010900 Lawrence et al. cited by other","US
      6292768 B1 20010900 Chan cited by other","US 6308171 B1 20011000 De La Huerga
      cited by other","US 6311177 B1 20011000 Dauerer et al. cited by other","US 6311194
      B1 20011000 Sheth et al. cited by other","US 6323853 B1 20011100 Hedloy cited
      by other","US 6338059 B1 20020100 Fields et al. cited by other","US 6373502
      B1 20020400 Nielsen cited by other","US 6438545 B1 20020800 Beauregard et al.
      cited by other","US 6442545 B1 20020800 Feldman et al. cited by other","US 6516321
      B1 20030200 De La Huerga cited by other","US 6519603 B1 20030200 Bays et al.
      cited by other","US 6556984 B1 20030400 Zien cited by other","US 6571241 B1
      20030500 Nosohara cited by other","US 6601026 B2 20030700 Appelt et al. cited
      by other","US 6618733 B1 20030900 White et al. cited by other","US 6625581 B1
      20030900 Perkowski cited by other","US 6629079 B1 20030900 Spiegel et al. cited
      by other","US 6651059 B1 20031100 Sundaresan et al. cited by other","US 6697824
      B1 20040200 Bowman-Amuah cited by other","US 6732090 B2 20040500 Shanahan et
      al. cited by other","US 6732361 B1 20040500 Andreoli et al. cited by other","US
      7003522 B1 20060200 Reynar et al. cited by other","US 7032174 B2 20060400 Montero
      et al. cited by other","US 7130861 B2 20061000 Bookman et al. cited by other","US
      7287218 B1 20071000 Knotz et al. cited by other","US 7496854 B2 20090200 Hedloy
      cited by other","US RE40731 E 20090600 Bookman et al. cited by other","US 2002/0035581
      A1 20020300 Reynar et al. cited by other","US 2002/0036654 A1 20020300 Evans
      et al. cited by other","US 2002/0062353 A1 20020500 Konno et al. cited by other","US
      2002/0065891 A1 20020500 Malik cited by other","US 2002/0091803 A1 20020700
      Imamura et al. cited by other","US 2002/0099730 A1 20020700 Brown cited by other","US
      2002/0184247 A1 20021200 Jokela et al. cited by other","US 2003/0004909 A1 20030100
      Chauhan et al. cited by other","US 2003/0033290 A1 20030200 Garner et al. cited
      by other","US 2003/0154144 A1 20030800 Pokorny et al. cited by other","US 2003/0187587
      A1 20031000 Swindells et al. cited by other","US 2003/0212527 A1 20031100 Moore
      et al. cited by other"],"usRefIssueDate":["19750300","19790100","19820300","19830500","19870300","19870600","19870800","19880500","19880900","19890300","19890600","19890900","19890900","19890900","19891200","19900100","19900400","19900700","19900900","19901200","19910100","19910200","19910500","19911100","19920200","19920700","19920900","19920900","19920900","19921000","19930400","19930500","19930600","19930600","19930700","19930800","19930800","19931000","19931000","19931100","19940200","19940300","19940400","19940600","19940700","19940700","19940800","19940900","19940900","19941100","19941100","19941200","19941200","19950200","19950400","19950400","19950400","19950500","19950500","19950700","19950800","19951000","19951000","19960200","19960200","19960300","19960400","19960500","19960500","19960600","19960600","19960700","19960700","19960700","19960800","19960800","19961000","19961100","19961200","19961200","19970200","19970200","19970300","19970400","19970500","19970600","19970700","19970700","19970700","19970800","19970800","19970900","19971200","19980100","19980100","19980100","19980300","19980300","19980300","19980300","19980300","19980400","19980400","19980400","19980500","19980500","19980600","19980600","19980600","19980600","19980600","19980700","19980700","19980700","19980700","19980700","19980800","19980800","19980800","19980800","19980800","19980800","19980900","19980900","19980900","19980900","19980900","19981000","19981000","19981000","19981000","19981100","19981100","19981100","19981200","19981200","19990100","19990100","19990100","19990100","19990200","19990200","19990200","19990200","19990200","19990300","19990300","19990300","19990300","19990400","19990400","19990400","19990400","19990400","19990400","19990500","19990500","19990500","19990500","19990600","19990700","19990700","19990700","19990700","19990800","19990800","19990900","19991000","19991000","19991000","19991000","19991000","19991100","19991100","19991100","19991100","19991200","19991200","19991200","20000100","20000200","20000200","20000200","20000200","20000200","20000200","20000300","20000400","20000400","20000500","20000500","20000600","20000700","20000700","20000700","20000700","20000800","20000900","20001000","20001000","20001000","20001100","20001100","20010100","20010100","20010200","20010200","20010500","20010700","20010700","20010800","20010900","20010900","20011000","20011000","20011000","20011100","20020100","20020400","20020800","20020800","20030200","20030200","20030400","20030500","20030700","20030900","20030900","20030900","20031100","20040200","20040500","20040500","20060200","20060400","20061000","20071000","20090200","20090600","20020300","20020300","20020500","20020500","20020700","20020700","20021200","20030100","20030200","20030800","20031000","20031100"],"usRefIssueDateKwicHits":["19750300","19790100","19820300","19830500","19870300","19870600","19870800","19880500","19880900","19890300","19890600","19890900","19890900","19890900","19891200","19900100","19900400","19900700","19900900","19901200","19910100","19910200","19910500","19911100","19920200","19920700","19920900","19920900","19920900","19921000","19930400","19930500","19930600","19930600","19930700","19930800","19930800","19931000","19931000","19931100","19940200","19940300","19940400","19940600","19940700","19940700","19940800","19940900","19940900","19941100","19941100","19941200","19941200","19950200","19950400","19950400","19950400","19950500","19950500","19950700","19950800","19951000","19951000","19960200","19960200","19960300","19960400","19960500","19960500","19960600","19960600","19960700","19960700","19960700","19960800","19960800","19961000","19961100","19961200","19961200","19970200","19970200","19970300","19970400","19970500","19970600","19970700","19970700","19970700","19970800","19970800","19970900","19971200","19980100","19980100","19980100","19980300","19980300","19980300","19980300","19980300","19980400","19980400","19980400","19980500","19980500","19980600","19980600","19980600","19980600","19980600","19980700","19980700","19980700","19980700","19980700","19980800","19980800","19980800","19980800","19980800","19980800","19980900","19980900","19980900","19980900","19980900","19981000","19981000","19981000","19981000","19981100","19981100","19981100","19981200","19981200","19990100","19990100","19990100","19990100","19990200","19990200","19990200","19990200","19990200","19990300","19990300","19990300","19990300","19990400","19990400","19990400","19990400","19990400","19990400","19990500","19990500","19990500","19990500","19990600","19990700","19990700","19990700","19990700","19990800","19990800","19990900","19991000","19991000","19991000","19991000","19991000","19991100","19991100","19991100","19991100","19991200","19991200","19991200","20000100","20000200","20000200","20000200","20000200","20000200","20000200","20000300","20000400","20000400","20000500","20000500","20000600","20000700","20000700","20000700","20000700","20000800","20000900","20001000","20001000","20001000","20001100","20001100","20010100","20010100","20010200","20010200","20010500","20010700","20010700","20010800","20010900","20010900","20011000","20011000","20011000","20011100","20020100","20020400","20020800","20020800","20030200","20030200","20030400","20030500","20030700","20030900","20030900","20030900","20031100","20040200","20040500","20040500","20060200","20060400","20061000","20071000","20090200","20090600","20020300","20020300","20020500","20020500","20020700","20020700","20021200","20030100","20030200","20030800","20031000","20031100"],"usRefPatenteeName":["Mitchell,
      Jr. et al.","Kolpek et al.","Millett et al.","Walton","Suzuki et al.","Lange
      et al.","Heard et al.","Yoshimura","Kucera et al.","Komatsu et al.","Freeny,
      Jr.","Kucera et al.","Nishio","Kucera et al.","Zamora et al.","Beck et al.","Swinehart
      et al.","Bodick et al.","Tawara et al.","Kojima","Jordan","Hutchins","Ogawa","Garcia","Spielman
      et al.","Sadler","Jachmann et al.","Cassorla et al.","Matsui","Nagashima","Bernstein
      et al.","Miike et al.","Chung","Sakai et al.","Miklos","Doyle","Reed et al.","Nolan
      et al.","Gildea et al.","Buchanan et al.","Yokogawa","Bernstein et al.","Neumann","Servi","Kugimiya
      et al.","Hashimoto et al.","Hofert et al.","Takeda et al.","Kondo","Doue","Cohen
      et al.","Dugan et al.","Vasudevan","Chalas","Rosenbaum","Fujisawa et al.","Oren
      et al.","Torres","Krawchuk et al.","Loucks et al.","Richichi et al.","Vanderdrift","Brunett
      et al.","Douglas et al.","Douglas et al.","Sharma et al.","Miller","Chuah et
      al.","Ozawa et al.","Meske, Jr. et al.","Schell et al.","Teraoka et al.","Amado","Church
      et al.","Skarbo et al.","Bowers et al.","Nemoto et al.","Newbold et al.","Kotake
      et al.","Chou","Tabb et al.","Hidaka","Dockter et al.","Hong et al.","Nerlikar","Dickinson","Kiuchi","Van
      De Velde","Mogilevsky","Davis et al.","Redpath","Capps","Wical","Goodwin et
      al.","Wical","Sotomayor","Hargrave, III et al.","Cuthbertson et al.","Barrett
      et al.","Liaguno et al.","Dickinson","Minor et al.","Leone","Anderson et al.","Kaplan
      et al.","Gadol","Nielsen","Ben-Shachar","Bertoni","Rayson","Edelstein et al.","Light","Holleran
      et al.","Shoji et al.","Oren et al.","Kaplan et al.","Shane","Dahlgren et al.","French
      et al.","Kikinis","Siegel","Johnson et al.","Bailey","Skarbo et al.","Miller","Rivette
      et al.","Anthony","Ferguson et al.","Van Hoff","Bookman et al.","Snelling, Jr.","Anand
      et al.","Nadel et al.","Skarbo et al.","Fredenburg","Jovicic et al.","Pandit","Ferrel
      et al.","Reed et al.","Horvitz et al.","Yamabana","Knutson","Borovoy et al.","Nielsen","Brown
      et al.","Ferrel et al.","Christy","Ho","Vanechanos, Jr.","Nielsen","Wills","De
      La Huerga et al.","Miller et al.","Ramos et al.","Pace et al.","Gipson","Nakabayashi
      et al.","Reynolds","Miyasaka et al.","Madnnick et al.","Li","Krellenstein","Evans
      et al.","Milewski et al.","Zucknovich et al.","Miller et al.","Wical","Sotomayor","Liddy
      et al.","Nielsen et al.","Ebrahim","Beauregard et al.","Yokoyama et al.","Sugimura","Niwa
      et al.","Murai","Bliss et al.","Breese et al.","Poole et al.","Hayashi et al.","Horvitz
      et al.","Guinan","Rostoker et al.","Brown et al.","Conrad et al.","Hugh","Parks","Kumano
      et al.","Bennett et al.","Wical","Horvitz","Paik et al.","Tso","Horvitz","Rodkin
      et al.","Bowen et al.","Murakami et al.","Horowitz et al.","Ando","Ikeno","Zhilyaev","Teare
      et al.","Call","Saitoh","Horvitz","Snow et al.","McIntosh","Horvits et al.","Horvitz
      et al.","Horvitz et al.","De La Huerga","Lawrence et al.","Chan","De La Huerga","Dauerer
      et al.","Sheth et al.","Hedloy","Fields et al.","Nielsen","Beauregard et al.","Feldman
      et al.","De La Huerga","Bays et al.","Zien","Nosohara","Appelt et al.","White
      et al.","Perkowski","Spiegel et al.","Sundaresan et al.","Bowman-Amuah","Shanahan
      et al.","Andreoli et al.","Reynar et al.","Montero et al.","Bookman et al.","Knotz
      et al.","Hedloy","Bookman et al.","Reynar et al.","Evans et al.","Konno et al.","Malik","Imamura
      et al.","Brown","Jokela et al.","Chauhan et al.","Garner et al.","Pokorny et
      al.","Swindells et al.","Moore et al."],"volumeNumber":null,"correspondenceNameAddress":null,"correspondenceAddressCustomerNumber":null,"ibmtdbAccessionNumber":null,"inventorsName":["Bookman;
      Marc","Yamanaka; Brian"],"applicationKindCode":"E","inventorNameDerived":null,"intlPubClassificationClass":["G06F","G06F"],"issuedUsOrigClassification":"704/3","curCpcSubclassFull":["G09B"],"cpcCurAdditionalClass":null,"cpcCurInventiveClass":["G09B","G09B"],"cpcCurClassificationGroup":["G
      G09B G09B19/06 20130101 L I B H 20191011 US","G G09B G09B5/065 20130101 F I
      B H 20190822 US"],"curCpcClassificationFull":["G09B5/065 20130101","G09B19/06
      20130101"],"cpcCombinationClassificationCur":null,"cpcCombinationTallyCur":null,"intlFurtherClassification":null,"currentUsPatentClass":["345","704","707","715"],"idWithoutSolrPartition":"US-US-RE043633","curIntlPatentClassifictionPrimaryDateKwicHits":null,"curIntlPatentClssifSecHlights":null,"internationalClassificationInfom":null,"cpcOrigInventvClssifHlghts":null,"descriptionStart":10,"descriptionEnd":15,"publicationReferenceDocumentNumberOne":"RE043633"}'
    headers:
      content-type:
      - application/json
      date:
      - Tue, 07 Nov 2023 19:15:59 GMT
      server-timing:
      - intid;desc=7a874c82c7feb6e7
    http_version: HTTP/2
    status_code: 200
version: 1
